{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LeNet网络对MNIST进行分类\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.全局设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 32*32\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 32, 32])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "resize_transform = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='/data/input/', \n",
    "                               train=True, \n",
    "                               transform=resize_transform,\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='/data/input/', \n",
    "                              train=False, \n",
    "                              transform=resize_transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE)\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if self.grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(NUM_CLASSES, GRAYSCALE)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/0469 | Cost: 2.3055\n",
      "Epoch: 001/010 | Batch 0050/0469 | Cost: 0.5466\n",
      "Epoch: 001/010 | Batch 0100/0469 | Cost: 0.3708\n",
      "Epoch: 001/010 | Batch 0150/0469 | Cost: 0.3409\n",
      "Epoch: 001/010 | Batch 0200/0469 | Cost: 0.1298\n",
      "Epoch: 001/010 | Batch 0250/0469 | Cost: 0.1857\n",
      "Epoch: 001/010 | Batch 0300/0469 | Cost: 0.0940\n",
      "Epoch: 001/010 | Batch 0350/0469 | Cost: 0.1852\n",
      "Epoch: 001/010 | Batch 0400/0469 | Cost: 0.1425\n",
      "Epoch: 001/010 | Batch 0450/0469 | Cost: 0.0623\n",
      "Epoch: 001/010 | Train: 96.657%\n",
      "Time elapsed: 0.33 min\n",
      "Epoch: 002/010 | Batch 0000/0469 | Cost: 0.0658\n",
      "Epoch: 002/010 | Batch 0050/0469 | Cost: 0.1021\n",
      "Epoch: 002/010 | Batch 0100/0469 | Cost: 0.0813\n",
      "Epoch: 002/010 | Batch 0150/0469 | Cost: 0.1711\n",
      "Epoch: 002/010 | Batch 0200/0469 | Cost: 0.0637\n",
      "Epoch: 002/010 | Batch 0250/0469 | Cost: 0.0768\n",
      "Epoch: 002/010 | Batch 0300/0469 | Cost: 0.0423\n",
      "Epoch: 002/010 | Batch 0350/0469 | Cost: 0.0944\n",
      "Epoch: 002/010 | Batch 0400/0469 | Cost: 0.0304\n",
      "Epoch: 002/010 | Batch 0450/0469 | Cost: 0.0685\n",
      "Epoch: 002/010 | Train: 98.223%\n",
      "Time elapsed: 0.56 min\n",
      "Epoch: 003/010 | Batch 0000/0469 | Cost: 0.0861\n",
      "Epoch: 003/010 | Batch 0050/0469 | Cost: 0.0318\n",
      "Epoch: 003/010 | Batch 0100/0469 | Cost: 0.0311\n",
      "Epoch: 003/010 | Batch 0150/0469 | Cost: 0.0586\n",
      "Epoch: 003/010 | Batch 0200/0469 | Cost: 0.0508\n",
      "Epoch: 003/010 | Batch 0250/0469 | Cost: 0.0484\n",
      "Epoch: 003/010 | Batch 0300/0469 | Cost: 0.0492\n",
      "Epoch: 003/010 | Batch 0350/0469 | Cost: 0.1144\n",
      "Epoch: 003/010 | Batch 0400/0469 | Cost: 0.0165\n",
      "Epoch: 003/010 | Batch 0450/0469 | Cost: 0.0302\n",
      "Epoch: 003/010 | Train: 98.735%\n",
      "Time elapsed: 0.77 min\n",
      "Epoch: 004/010 | Batch 0000/0469 | Cost: 0.1140\n",
      "Epoch: 004/010 | Batch 0050/0469 | Cost: 0.0241\n",
      "Epoch: 004/010 | Batch 0100/0469 | Cost: 0.0169\n",
      "Epoch: 004/010 | Batch 0150/0469 | Cost: 0.0100\n",
      "Epoch: 004/010 | Batch 0200/0469 | Cost: 0.0485\n",
      "Epoch: 004/010 | Batch 0250/0469 | Cost: 0.0431\n",
      "Epoch: 004/010 | Batch 0300/0469 | Cost: 0.0156\n",
      "Epoch: 004/010 | Batch 0350/0469 | Cost: 0.0606\n",
      "Epoch: 004/010 | Batch 0400/0469 | Cost: 0.0334\n",
      "Epoch: 004/010 | Batch 0450/0469 | Cost: 0.1407\n",
      "Epoch: 004/010 | Train: 98.907%\n",
      "Time elapsed: 0.99 min\n",
      "Epoch: 005/010 | Batch 0000/0469 | Cost: 0.0129\n",
      "Epoch: 005/010 | Batch 0050/0469 | Cost: 0.0526\n",
      "Epoch: 005/010 | Batch 0100/0469 | Cost: 0.0503\n",
      "Epoch: 005/010 | Batch 0150/0469 | Cost: 0.0052\n",
      "Epoch: 005/010 | Batch 0200/0469 | Cost: 0.0449\n",
      "Epoch: 005/010 | Batch 0250/0469 | Cost: 0.0046\n",
      "Epoch: 005/010 | Batch 0300/0469 | Cost: 0.0513\n",
      "Epoch: 005/010 | Batch 0350/0469 | Cost: 0.0692\n",
      "Epoch: 005/010 | Batch 0400/0469 | Cost: 0.0783\n",
      "Epoch: 005/010 | Batch 0450/0469 | Cost: 0.0186\n",
      "Epoch: 005/010 | Train: 99.378%\n",
      "Time elapsed: 1.20 min\n",
      "Epoch: 006/010 | Batch 0000/0469 | Cost: 0.0368\n",
      "Epoch: 006/010 | Batch 0050/0469 | Cost: 0.0071\n",
      "Epoch: 006/010 | Batch 0100/0469 | Cost: 0.0164\n",
      "Epoch: 006/010 | Batch 0150/0469 | Cost: 0.0711\n",
      "Epoch: 006/010 | Batch 0200/0469 | Cost: 0.0099\n",
      "Epoch: 006/010 | Batch 0250/0469 | Cost: 0.0347\n",
      "Epoch: 006/010 | Batch 0300/0469 | Cost: 0.0043\n",
      "Epoch: 006/010 | Batch 0350/0469 | Cost: 0.0232\n",
      "Epoch: 006/010 | Batch 0400/0469 | Cost: 0.0091\n",
      "Epoch: 006/010 | Batch 0450/0469 | Cost: 0.0918\n",
      "Epoch: 006/010 | Train: 99.445%\n",
      "Time elapsed: 1.40 min\n",
      "Epoch: 007/010 | Batch 0000/0469 | Cost: 0.0094\n",
      "Epoch: 007/010 | Batch 0050/0469 | Cost: 0.0073\n",
      "Epoch: 007/010 | Batch 0100/0469 | Cost: 0.0051\n",
      "Epoch: 007/010 | Batch 0150/0469 | Cost: 0.0114\n",
      "Epoch: 007/010 | Batch 0200/0469 | Cost: 0.0283\n",
      "Epoch: 007/010 | Batch 0250/0469 | Cost: 0.0227\n",
      "Epoch: 007/010 | Batch 0300/0469 | Cost: 0.0290\n",
      "Epoch: 007/010 | Batch 0350/0469 | Cost: 0.0065\n",
      "Epoch: 007/010 | Batch 0400/0469 | Cost: 0.0243\n",
      "Epoch: 007/010 | Batch 0450/0469 | Cost: 0.0029\n",
      "Epoch: 007/010 | Train: 99.575%\n",
      "Time elapsed: 1.61 min\n",
      "Epoch: 008/010 | Batch 0000/0469 | Cost: 0.0031\n",
      "Epoch: 008/010 | Batch 0050/0469 | Cost: 0.0056\n",
      "Epoch: 008/010 | Batch 0100/0469 | Cost: 0.0036\n",
      "Epoch: 008/010 | Batch 0150/0469 | Cost: 0.0078\n",
      "Epoch: 008/010 | Batch 0200/0469 | Cost: 0.0308\n",
      "Epoch: 008/010 | Batch 0250/0469 | Cost: 0.0177\n",
      "Epoch: 008/010 | Batch 0300/0469 | Cost: 0.0055\n",
      "Epoch: 008/010 | Batch 0350/0469 | Cost: 0.0088\n",
      "Epoch: 008/010 | Batch 0400/0469 | Cost: 0.0198\n",
      "Epoch: 008/010 | Batch 0450/0469 | Cost: 0.0100\n",
      "Epoch: 008/010 | Train: 99.753%\n",
      "Time elapsed: 1.81 min\n",
      "Epoch: 009/010 | Batch 0000/0469 | Cost: 0.0016\n",
      "Epoch: 009/010 | Batch 0050/0469 | Cost: 0.0037\n",
      "Epoch: 009/010 | Batch 0100/0469 | Cost: 0.0069\n",
      "Epoch: 009/010 | Batch 0150/0469 | Cost: 0.0007\n",
      "Epoch: 009/010 | Batch 0200/0469 | Cost: 0.0142\n",
      "Epoch: 009/010 | Batch 0250/0469 | Cost: 0.0141\n",
      "Epoch: 009/010 | Batch 0300/0469 | Cost: 0.0034\n",
      "Epoch: 009/010 | Batch 0350/0469 | Cost: 0.0042\n",
      "Epoch: 009/010 | Batch 0400/0469 | Cost: 0.0063\n",
      "Epoch: 009/010 | Batch 0450/0469 | Cost: 0.0011\n",
      "Epoch: 009/010 | Train: 99.787%\n",
      "Time elapsed: 2.03 min\n",
      "Epoch: 010/010 | Batch 0000/0469 | Cost: 0.0046\n",
      "Epoch: 010/010 | Batch 0050/0469 | Cost: 0.0339\n",
      "Epoch: 010/010 | Batch 0100/0469 | Cost: 0.0064\n",
      "Epoch: 010/010 | Batch 0150/0469 | Cost: 0.0203\n",
      "Epoch: 010/010 | Batch 0200/0469 | Cost: 0.0129\n",
      "Epoch: 010/010 | Batch 0250/0469 | Cost: 0.0189\n",
      "Epoch: 010/010 | Batch 0300/0469 | Cost: 0.0087\n",
      "Epoch: 010/010 | Batch 0350/0469 | Cost: 0.0071\n",
      "Epoch: 010/010 | Batch 0400/0469 | Cost: 0.0035\n",
      "Epoch: 010/010 | Batch 0450/0469 | Cost: 0.0081\n",
      "Epoch: 010/010 | Train: 99.837%\n",
      "Time elapsed: 2.24 min\n",
      "Total Training Time: 2.24 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.81%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7d17ec24a8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "nhwc_img = np.transpose(features[0], axes=(1, 2, 0))\n",
    "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
    "plt.imshow(nhw_img, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability 7 100.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(device)[0, None])\n",
    "print('Probability 7 %.2f%%' % (probas[0][7]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
