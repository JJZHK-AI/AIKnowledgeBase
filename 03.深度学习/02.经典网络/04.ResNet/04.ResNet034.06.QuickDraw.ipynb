{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用ResNet34对QuickDraw进行分类\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.全局设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = True\n",
    "\n",
    "DATA_ROOT=os.path.join('/input', 'QuickDraw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7fa8233940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(DATA_ROOT, 'quickdraw_png_set1_train.csv'), index_col=0)\n",
    "df.head()\n",
    "\n",
    "main_dir = os.path.join(DATA_ROOT, 'images')\n",
    "\n",
    "img = Image.open(os.path.join(main_dir, df.index[99]))\n",
    "img = np.asarray(img, dtype=np.uint8)\n",
    "print(img.shape)\n",
    "plt.imshow(np.array(img), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickdrawDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Quickdraw images\"\"\"\n",
    "\n",
    "    def __init__(self, txt_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(txt_path, sep=\",\", index_col=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_path = txt_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "custom_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = QuickdrawDataset(txt_path=os.path.join(DATA_ROOT, 'quickdraw_png_set1_train.csv'),\n",
    "                                 img_dir=os.path.join(DATA_ROOT, 'images'),\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4) \n",
    "\n",
    "\n",
    "valid_dataset = QuickdrawDataset(txt_path=os.path.join(DATA_ROOT, 'quickdraw_png_set1_train.csv'),\n",
    "                                 img_dir=os.path.join(DATA_ROOT, 'images'),\n",
    "                                transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4) \n",
    "\n",
    "\n",
    "\n",
    "test_dataset = QuickdrawDataset(txt_path=os.path.join(DATA_ROOT, 'quickdraw_png_set1_train.csv'),\n",
    "                                 img_dir=os.path.join(DATA_ROOT, 'images'),\n",
    "                                transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, grayscale):\n",
    "        self.inplanes = 64\n",
    "        if grayscale:\n",
    "            in_dim = 1\n",
    "        else:\n",
    "            in_dim = 3\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, (2. / n)**.5)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        # because MNIST is already 1x1 here:\n",
    "        # disable avg pooling\n",
    "        #x = self.avgpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "\n",
    "\n",
    "def resnet34(num_classes):\n",
    "    \"\"\"Constructs a ResNet-34 model.\"\"\"\n",
    "    model = ResNet(block=BasicBlock, \n",
    "                   layers=[3, 4, 6, 3],\n",
    "                   num_classes=NUM_CLASSES,\n",
    "                   grayscale=GRAYSCALE)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = resnet34(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/8290 | Cost: 2.7658\n",
      "Epoch: 001/010 | Batch 0500/8290 | Cost: 0.4341\n",
      "Epoch: 001/010 | Batch 1000/8290 | Cost: 0.3806\n",
      "Epoch: 001/010 | Batch 1500/8290 | Cost: 0.4194\n",
      "Epoch: 001/010 | Batch 2000/8290 | Cost: 0.3328\n",
      "Epoch: 001/010 | Batch 2500/8290 | Cost: 0.4841\n",
      "Epoch: 001/010 | Batch 3000/8290 | Cost: 0.4001\n",
      "Epoch: 001/010 | Batch 3500/8290 | Cost: 0.1948\n",
      "Epoch: 001/010 | Batch 4000/8290 | Cost: 0.3536\n",
      "Epoch: 001/010 | Batch 4500/8290 | Cost: 0.2633\n",
      "Epoch: 001/010 | Batch 5000/8290 | Cost: 0.2803\n",
      "Epoch: 001/010 | Batch 5500/8290 | Cost: 0.3563\n",
      "Epoch: 001/010 | Batch 6000/8290 | Cost: 0.2477\n",
      "Epoch: 001/010 | Batch 6500/8290 | Cost: 0.3710\n",
      "Epoch: 001/010 | Batch 7000/8290 | Cost: 0.2519\n",
      "Epoch: 001/010 | Batch 7500/8290 | Cost: 0.2810\n",
      "Epoch: 001/010 | Batch 8000/8290 | Cost: 0.2190\n",
      "Epoch: 001/010 | Train: 93.225% | Validation: 93.225%\n",
      "Time elapsed: 15.07 min\n",
      "Epoch: 002/010 | Batch 0000/8290 | Cost: 0.2471\n",
      "Epoch: 002/010 | Batch 0500/8290 | Cost: 0.2490\n",
      "Epoch: 002/010 | Batch 1000/8290 | Cost: 0.3186\n",
      "Epoch: 002/010 | Batch 1500/8290 | Cost: 0.2916\n",
      "Epoch: 002/010 | Batch 2000/8290 | Cost: 0.2028\n",
      "Epoch: 002/010 | Batch 2500/8290 | Cost: 0.0906\n",
      "Epoch: 002/010 | Batch 3000/8290 | Cost: 0.2575\n",
      "Epoch: 002/010 | Batch 3500/8290 | Cost: 0.2764\n",
      "Epoch: 002/010 | Batch 4000/8290 | Cost: 0.2678\n",
      "Epoch: 002/010 | Batch 4500/8290 | Cost: 0.1767\n",
      "Epoch: 002/010 | Batch 5000/8290 | Cost: 0.2120\n",
      "Epoch: 002/010 | Batch 5500/8290 | Cost: 0.2360\n",
      "Epoch: 002/010 | Batch 6000/8290 | Cost: 0.2458\n",
      "Epoch: 002/010 | Batch 6500/8290 | Cost: 0.3051\n",
      "Epoch: 002/010 | Batch 7000/8290 | Cost: 0.1028\n",
      "Epoch: 002/010 | Batch 7500/8290 | Cost: 0.1715\n",
      "Epoch: 002/010 | Batch 8000/8290 | Cost: 0.1688\n",
      "Epoch: 002/010 | Train: 94.634% | Validation: 94.634%\n",
      "Time elapsed: 26.02 min\n",
      "Epoch: 003/010 | Batch 0000/8290 | Cost: 0.1493\n",
      "Epoch: 003/010 | Batch 0500/8290 | Cost: 0.1463\n",
      "Epoch: 003/010 | Batch 1000/8290 | Cost: 0.3622\n",
      "Epoch: 003/010 | Batch 1500/8290 | Cost: 0.0860\n",
      "Epoch: 003/010 | Batch 2000/8290 | Cost: 0.2153\n",
      "Epoch: 003/010 | Batch 2500/8290 | Cost: 0.1526\n",
      "Epoch: 003/010 | Batch 3000/8290 | Cost: 0.1722\n",
      "Epoch: 003/010 | Batch 3500/8290 | Cost: 0.0818\n",
      "Epoch: 003/010 | Batch 4000/8290 | Cost: 0.1351\n",
      "Epoch: 003/010 | Batch 4500/8290 | Cost: 0.0935\n",
      "Epoch: 003/010 | Batch 5000/8290 | Cost: 0.2367\n",
      "Epoch: 003/010 | Batch 5500/8290 | Cost: 0.1906\n",
      "Epoch: 003/010 | Batch 6000/8290 | Cost: 0.0814\n",
      "Epoch: 003/010 | Batch 6500/8290 | Cost: 0.2433\n",
      "Epoch: 003/010 | Batch 7000/8290 | Cost: 0.2594\n",
      "Epoch: 003/010 | Batch 7500/8290 | Cost: 0.1188\n",
      "Epoch: 003/010 | Batch 8000/8290 | Cost: 0.2098\n",
      "Epoch: 003/010 | Train: 95.243% | Validation: 95.243%\n",
      "Time elapsed: 36.96 min\n",
      "Epoch: 004/010 | Batch 0000/8290 | Cost: 0.2032\n",
      "Epoch: 004/010 | Batch 0500/8290 | Cost: 0.2023\n",
      "Epoch: 004/010 | Batch 1000/8290 | Cost: 0.2049\n",
      "Epoch: 004/010 | Batch 1500/8290 | Cost: 0.1160\n",
      "Epoch: 004/010 | Batch 2000/8290 | Cost: 0.2096\n",
      "Epoch: 004/010 | Batch 2500/8290 | Cost: 0.1073\n",
      "Epoch: 004/010 | Batch 3000/8290 | Cost: 0.1187\n",
      "Epoch: 004/010 | Batch 3500/8290 | Cost: 0.1386\n",
      "Epoch: 004/010 | Batch 4000/8290 | Cost: 0.2144\n",
      "Epoch: 004/010 | Batch 4500/8290 | Cost: 0.2075\n",
      "Epoch: 004/010 | Batch 5000/8290 | Cost: 0.1056\n",
      "Epoch: 004/010 | Batch 5500/8290 | Cost: 0.1951\n",
      "Epoch: 004/010 | Batch 6000/8290 | Cost: 0.2387\n",
      "Epoch: 004/010 | Batch 6500/8290 | Cost: 0.1188\n",
      "Epoch: 004/010 | Batch 7000/8290 | Cost: 0.2581\n",
      "Epoch: 004/010 | Batch 7500/8290 | Cost: 0.0505\n",
      "Epoch: 004/010 | Batch 8000/8290 | Cost: 0.1895\n",
      "Epoch: 004/010 | Train: 95.819% | Validation: 95.819%\n",
      "Time elapsed: 47.87 min\n",
      "Epoch: 005/010 | Batch 0000/8290 | Cost: 0.1141\n",
      "Epoch: 005/010 | Batch 0500/8290 | Cost: 0.2184\n",
      "Epoch: 005/010 | Batch 1000/8290 | Cost: 0.1340\n",
      "Epoch: 005/010 | Batch 1500/8290 | Cost: 0.0641\n",
      "Epoch: 005/010 | Batch 2000/8290 | Cost: 0.2112\n",
      "Epoch: 005/010 | Batch 2500/8290 | Cost: 0.0963\n",
      "Epoch: 005/010 | Batch 3000/8290 | Cost: 0.1023\n",
      "Epoch: 005/010 | Batch 3500/8290 | Cost: 0.1948\n",
      "Epoch: 005/010 | Batch 4000/8290 | Cost: 0.1165\n",
      "Epoch: 005/010 | Batch 4500/8290 | Cost: 0.1412\n",
      "Epoch: 005/010 | Batch 5000/8290 | Cost: 0.1080\n",
      "Epoch: 005/010 | Batch 5500/8290 | Cost: 0.1006\n",
      "Epoch: 005/010 | Batch 6000/8290 | Cost: 0.0878\n",
      "Epoch: 005/010 | Batch 6500/8290 | Cost: 0.2214\n",
      "Epoch: 005/010 | Batch 7000/8290 | Cost: 0.0943\n",
      "Epoch: 005/010 | Batch 7500/8290 | Cost: 0.1109\n",
      "Epoch: 005/010 | Batch 8000/8290 | Cost: 0.0283\n",
      "Epoch: 005/010 | Train: 96.224% | Validation: 96.224%\n",
      "Time elapsed: 58.64 min\n",
      "Epoch: 006/010 | Batch 0000/8290 | Cost: 0.1570\n",
      "Epoch: 006/010 | Batch 0500/8290 | Cost: 0.1371\n",
      "Epoch: 006/010 | Batch 1000/8290 | Cost: 0.1194\n",
      "Epoch: 006/010 | Batch 1500/8290 | Cost: 0.1584\n",
      "Epoch: 006/010 | Batch 2000/8290 | Cost: 0.1211\n",
      "Epoch: 006/010 | Batch 2500/8290 | Cost: 0.1341\n",
      "Epoch: 006/010 | Batch 3000/8290 | Cost: 0.1259\n",
      "Epoch: 006/010 | Batch 3500/8290 | Cost: 0.0911\n",
      "Epoch: 006/010 | Batch 4000/8290 | Cost: 0.1122\n",
      "Epoch: 006/010 | Batch 4500/8290 | Cost: 0.1972\n",
      "Epoch: 006/010 | Batch 5000/8290 | Cost: 0.0844\n",
      "Epoch: 006/010 | Batch 5500/8290 | Cost: 0.1431\n",
      "Epoch: 006/010 | Batch 6000/8290 | Cost: 0.0977\n",
      "Epoch: 006/010 | Batch 6500/8290 | Cost: 0.0925\n",
      "Epoch: 006/010 | Batch 7000/8290 | Cost: 0.1351\n",
      "Epoch: 006/010 | Batch 7500/8290 | Cost: 0.1164\n",
      "Epoch: 006/010 | Batch 8000/8290 | Cost: 0.0931\n",
      "Epoch: 006/010 | Train: 96.494% | Validation: 96.494%\n",
      "Time elapsed: 69.42 min\n",
      "Epoch: 007/010 | Batch 0000/8290 | Cost: 0.1320\n",
      "Epoch: 007/010 | Batch 0500/8290 | Cost: 0.0926\n",
      "Epoch: 007/010 | Batch 1000/8290 | Cost: 0.0662\n",
      "Epoch: 007/010 | Batch 1500/8290 | Cost: 0.0896\n",
      "Epoch: 007/010 | Batch 2000/8290 | Cost: 0.1010\n",
      "Epoch: 007/010 | Batch 2500/8290 | Cost: 0.2068\n",
      "Epoch: 007/010 | Batch 3000/8290 | Cost: 0.1114\n",
      "Epoch: 007/010 | Batch 3500/8290 | Cost: 0.1474\n",
      "Epoch: 007/010 | Batch 4000/8290 | Cost: 0.1325\n",
      "Epoch: 007/010 | Batch 4500/8290 | Cost: 0.1349\n",
      "Epoch: 007/010 | Batch 5000/8290 | Cost: 0.1822\n",
      "Epoch: 007/010 | Batch 5500/8290 | Cost: 0.1963\n",
      "Epoch: 007/010 | Batch 6000/8290 | Cost: 0.0754\n",
      "Epoch: 007/010 | Batch 6500/8290 | Cost: 0.0716\n",
      "Epoch: 007/010 | Batch 7000/8290 | Cost: 0.1033\n",
      "Epoch: 007/010 | Batch 7500/8290 | Cost: 0.1055\n",
      "Epoch: 007/010 | Batch 8000/8290 | Cost: 0.1023\n",
      "Epoch: 007/010 | Train: 96.758% | Validation: 96.758%\n",
      "Time elapsed: 80.27 min\n",
      "Epoch: 008/010 | Batch 0000/8290 | Cost: 0.1139\n",
      "Epoch: 008/010 | Batch 0500/8290 | Cost: 0.1072\n",
      "Epoch: 008/010 | Batch 1000/8290 | Cost: 0.1002\n",
      "Epoch: 008/010 | Batch 1500/8290 | Cost: 0.1056\n",
      "Epoch: 008/010 | Batch 2000/8290 | Cost: 0.0697\n",
      "Epoch: 008/010 | Batch 2500/8290 | Cost: 0.0680\n",
      "Epoch: 008/010 | Batch 3000/8290 | Cost: 0.1893\n",
      "Epoch: 008/010 | Batch 3500/8290 | Cost: 0.1242\n",
      "Epoch: 008/010 | Batch 4000/8290 | Cost: 0.1291\n",
      "Epoch: 008/010 | Batch 4500/8290 | Cost: 0.1399\n",
      "Epoch: 008/010 | Batch 5000/8290 | Cost: 0.2044\n",
      "Epoch: 008/010 | Batch 5500/8290 | Cost: 0.0651\n",
      "Epoch: 008/010 | Batch 6000/8290 | Cost: 0.0400\n",
      "Epoch: 008/010 | Batch 6500/8290 | Cost: 0.0996\n",
      "Epoch: 008/010 | Batch 7000/8290 | Cost: 0.1107\n",
      "Epoch: 008/010 | Batch 7500/8290 | Cost: 0.0882\n",
      "Epoch: 008/010 | Batch 8000/8290 | Cost: 0.0534\n",
      "Epoch: 008/010 | Train: 97.231% | Validation: 97.231%\n",
      "Time elapsed: 91.09 min\n",
      "Epoch: 009/010 | Batch 0000/8290 | Cost: 0.0587\n",
      "Epoch: 009/010 | Batch 0500/8290 | Cost: 0.0574\n",
      "Epoch: 009/010 | Batch 1000/8290 | Cost: 0.0461\n",
      "Epoch: 009/010 | Batch 1500/8290 | Cost: 0.0901\n",
      "Epoch: 009/010 | Batch 2000/8290 | Cost: 0.1139\n",
      "Epoch: 009/010 | Batch 2500/8290 | Cost: 0.0932\n",
      "Epoch: 009/010 | Batch 3000/8290 | Cost: 0.1593\n",
      "Epoch: 009/010 | Batch 3500/8290 | Cost: 0.1292\n",
      "Epoch: 009/010 | Batch 4000/8290 | Cost: 0.2701\n",
      "Epoch: 009/010 | Batch 4500/8290 | Cost: 0.0934\n",
      "Epoch: 009/010 | Batch 5000/8290 | Cost: 0.1243\n",
      "Epoch: 009/010 | Batch 5500/8290 | Cost: 0.0457\n",
      "Epoch: 009/010 | Batch 6000/8290 | Cost: 0.0440\n",
      "Epoch: 009/010 | Batch 6500/8290 | Cost: 0.0722\n",
      "Epoch: 009/010 | Batch 7000/8290 | Cost: 0.0618\n",
      "Epoch: 009/010 | Batch 7500/8290 | Cost: 0.0700\n",
      "Epoch: 009/010 | Batch 8000/8290 | Cost: 0.0926\n",
      "Epoch: 009/010 | Train: 97.504% | Validation: 97.504%\n",
      "Time elapsed: 101.98 min\n",
      "Epoch: 010/010 | Batch 0000/8290 | Cost: 0.0872\n",
      "Epoch: 010/010 | Batch 0500/8290 | Cost: 0.0599\n",
      "Epoch: 010/010 | Batch 1000/8290 | Cost: 0.0861\n",
      "Epoch: 010/010 | Batch 1500/8290 | Cost: 0.0579\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010/010 | Batch 2000/8290 | Cost: 0.0860\n",
      "Epoch: 010/010 | Batch 2500/8290 | Cost: 0.0192\n",
      "Epoch: 010/010 | Batch 3000/8290 | Cost: 0.0916\n",
      "Epoch: 010/010 | Batch 3500/8290 | Cost: 0.1194\n",
      "Epoch: 010/010 | Batch 4000/8290 | Cost: 0.0816\n",
      "Epoch: 010/010 | Batch 4500/8290 | Cost: 0.0585\n",
      "Epoch: 010/010 | Batch 5000/8290 | Cost: 0.0901\n",
      "Epoch: 010/010 | Batch 5500/8290 | Cost: 0.0681\n",
      "Epoch: 010/010 | Batch 6000/8290 | Cost: 0.1458\n",
      "Epoch: 010/010 | Batch 6500/8290 | Cost: 0.0787\n",
      "Epoch: 010/010 | Batch 7000/8290 | Cost: 0.1260\n",
      "Epoch: 010/010 | Batch 7500/8290 | Cost: 0.1415\n",
      "Epoch: 010/010 | Batch 8000/8290 | Cost: 0.1003\n",
      "Epoch: 010/010 | Train: 97.867% | Validation: 97.867%\n",
      "Time elapsed: 112.84 min\n",
      "Total Training Time: 112.84 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 500:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "        \n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% | Validation: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE),\n",
    "              compute_accuracy(model, valid_loader, device=DEVICE)))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.87%\n"
     ]
    }
   ],
   "source": [
    "with torch.set_grad_enabled(False): # save memory during inference\n",
    "    print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader, device=DEVICE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_loader):\n",
    "\n",
    "    features = features\n",
    "    targets = targets\n",
    "    break\n",
    "    \n",
    "    \n",
    "nhwc_img = np.transpose(features[5], axes=(1, 2, 0))\n",
    "nhw_img = np.squeeze(nhwc_img.numpy(), axis=2)\n",
    "plt.imshow(nhw_img, cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Washing Machine 0.00%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "logits, probas = model(features.to(device)[0, None])\n",
    "print('Probability Washing Machine %.2f%%' % (probas[0][4]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
