{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "卷积神经网络之卷积层\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "接下来我将会介绍卷积层、池化层、正则化层、Dropout层、激活层、全连接层、损失函数的前向算法、后向算法以及梯度计算，我们使用的是$224,224,3$的图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1.卷积层的意义\n",
    "卷积层只要是为了提取图片的特征，它传统神经网络的优势在于可以有效的减少计算量。卷积层的输入时上一层所输出的特征图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2.卷积层的特点\n",
    "- 局部连接：这个是最容易想到的，每个神经元不再和上一层的所有神经元相连，而只和一小部分神经元相连。这样就减少了很多参数。\n",
    "- 权值共享：一组连接可以共享同一个权重，而不是每个连接有一个不同的权重，这样又减少了很多参数。\n",
    "- 下采样：可以使用Pooling来减少每层的样本数，进一步减少参数数量，同时还可以提升模型的鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3.卷积层的关键参数\n",
    "- 输入通道：即输入数据的神经元个数\n",
    "- 输出通道：即输出数据的神经元个数\n",
    "- 卷积核大小：即参与操作的卷积核的大小\n",
    "- 步长：即没做完一步操作，需要跨几个像素去寻找下一个卷积核\n",
    "- 是否需要扩充图片"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4.卷积的效果图\n",
    "我们可以先看一下用纯numpy实现的一个卷积层的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ELib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d82fa4e1edb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mELib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_layer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mepcl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mELib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mepcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ELib'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "import ELib.pyn.cnn.python_layer as epcl\n",
    "import ELib.pyn.cnn.functions as epcf\n",
    "\n",
    "plt.figure(figsize=(10,10), facecolor='w')\n",
    "imagePath = \"data/ConvVisible01.jpg\"\n",
    "img = cv2.imread(imagePath)\n",
    "basicImage = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "originImg = cv2.resize(basicImage, (224,224))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title('Origin')\n",
    "plt.imshow(originImg)\n",
    "\n",
    "conv1 = epcl.Conv2D(3, 64, 3, 1, 'SAME')\n",
    "img = epcf.preprocess_image(basicImage).transpose((0, 2, 3, 1))\n",
    "features = conv1(img)\n",
    "feature = features[:, :, :,0]\n",
    "feature = np.reshape(feature, newshape=(feature.shape[1], feature.shape[2]))\n",
    "feature = 1.0 / (1 + np.exp(-1 * feature))\n",
    "feature = np.round(feature * 255)\n",
    "plt.subplot(1,3,2)\n",
    "plt.title('Conv2D')\n",
    "plt.imshow(feature, cmap='gray')\n",
    "\n",
    "model = models.vgg16(pretrained=True).features\n",
    "img = epcf.preprocess_image(basicImage)\n",
    "features = model[0](torch.autograd.Variable(torch.FloatTensor(img)))\n",
    "feature = features[:, 0, :, :]\n",
    "feature = feature.view(feature.shape[1], feature.shape[2])\n",
    "feature = feature.data.numpy()\n",
    "feature = 1.0 / (1 + np.exp(-1 * feature))\n",
    "feature = np.round(feature * 255)\n",
    "plt.subplot(1,3,3)\n",
    "plt.title('Pytorch Conv2D')\n",
    "plt.imshow(feature, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们可以直观的看到原图和经过一层卷积之后的效果图的比较，下面我们来介绍如何进行卷积层具体的操作，也就是平时我们所说的前向算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "注：之所以后两张图差别较大，是因为我们的卷积层所用到的权重是没有经过训练的，而后一个是经过训练之后的权重。并且由于我们的权重初始化是随机的，所以每次运行的效果可能都不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5.卷积层的前向算法-forward\n",
    "卷积层的前向计算就是进行卷积计算的过程，我们知道下一个神经元的输出就是\n",
    "$$\\phi_i=\\omega_i \\bullet x + b$$\n",
    "对于整个特征图来说，就是\n",
    "$$\\vec{\\Phi}=\\vec{\\omega} \\bullet \\vec{x}+\\vec{b}$$\n",
    "假设我们的输入特征图为$bs,224,224, 3$(bs为图片张数,224为尺寸大小,3为通道数-RGB)，输出神经元output_channel=64，卷积核大小ksize=3，步长strid=1，补齐，name最终输出的结果就应该是$bs,224,224,64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "卷计算法真正的核心是函数_im2col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def _im2col(image, ksize, stride):\n",
    "    # image is a 4d tensor([batchsize, width ,height, channel])\n",
    "    image_col = []\n",
    "    for i in range(0, image.shape[1] - ksize + 1, stride):\n",
    "        for j in range(0, image.shape[2] - ksize + 1, stride):\n",
    "            col = image[:, i:i + ksize, j:j + ksize, :].reshape([-1])\n",
    "            image_col.append(col)\n",
    "    image_col = np.array(image_col)\n",
    "\n",
    "    return image_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "输入image是单张图片的数据，这里应该是$226,226,3$,ksize=3,stride=1,循环行与列，每次取到一个#3,3,3#的图像区块数据，然后reshape到一维，也就是$(27)$，然后将所有的卷积结果放在一起转化为array，就目前来说，结果是\n",
    "$$((226-3+1) * (226-3+1), 27)=(50176, 27)$$\n",
    "相当于最后得到了50176块图像区块，每个区块的大小为27维。这里为何是226呢，这是因为我们选择了补齐，所以卷积之前或对图片进行扩充。\n",
    "接下来我们需要做的就是\n",
    "$$\\vec{\\Phi}=\\vec{\\omega} \\bullet \\vec{x}+\\vec{b}$$\n",
    "如果是第一次调用，那么我们默认会对权重和偏执进行初始化，我们使用的是MSRA初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col_image_i = None\n",
    "col_weights = None\n",
    "bias = None\n",
    "np.dot(col_image_i, col_weights) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "col_image_i就是我们上面的卷积的结果，$shape=50176,27$，col_weights是权重，$shape=(27,64)$，bias是偏执，$shape=(64)$，64就是输出神经元的个数，然后将结果reshape成$1,224,224,64$，然后放入一个数组"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "最后bs次，计算出这一批次所有的图片的卷积，合并在一起，reshape成$bs,224,224,64$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6.卷积层的梯度计算-gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7.卷积层的后向算法-backward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8.$3 \\times 3$卷积\n",
    "使用用$3 \\times 3$卷积来替代更大尺寸的卷积，那么有一个前提，就是要保证两者具有同样大小的输出和感受野。两个$3 \\times 3$的卷积才能代替一个$5 \\times 5$的卷积；三个$3 \\times 3$的卷积才能代替一个$7 \\times 7$的卷积。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用$3 \\times 3$的卷积的好处\n",
    "- 网络层数增加了，这增加了网络的非线性表达能力。\n",
    "- 参数变少了，两个$3 \\times 3$和一个$5 \\times 5$的参数比例为3×3×2/(5×5)=0.72，同样的三个$3 \\times 3$和一个$7 \\times 7$参数比例为3×3×3/(7×7)=0.55，将近一倍的压缩，这可是很大提升。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9.$1 \\times 1$卷积\n",
    "![image](Images/05_02_001.jpeg)\n",
    "- 实现了不同通道同一位置的信息融合，如上图，C2融合了C1不同通道同一位置的信息。\n",
    "- 可以实现通道数的降维或升维。$1 \\times 1 \\times n$，如果n小于之前通道数，则实现了降维，如果n大于之前通道数，则实现了升维。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.6.10-final"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}