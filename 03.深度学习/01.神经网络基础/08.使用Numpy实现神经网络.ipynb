{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Numpy实现神经网络\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入必要的库与包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from JLib.pyn.layers import Conv2D, Relu, MaxPooling, FullyConnect, Softmax\n",
    "from jjzhk.progressbar import ProgressBar\n",
    "import time\n",
    "import struct\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.加载MNIST数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist(path, kind='train'):\n",
    "    \"\"\"Load MNIST data from `path`\"\"\"\n",
    "    images_path = glob('%s/%s*3-ubyte' % (path, kind))[0]\n",
    "    labels_path = glob('%s/%s*1-ubyte' % (path, kind))[0]\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II',\n",
    "                                 lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath,\n",
    "                             dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack('>IIII',\n",
    "                                               imgpath.read(16))\n",
    "        images = np.fromfile(imgpath,\n",
    "                             dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_mnist('/Users/JJZHK/data/input/MNIST/raw')\n",
    "test_images, test_labels = load_mnist('/Users/JJZHK/data/input/MNIST/raw', 't10k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.定义网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "conv1 = Conv2D([batch_size, 28, 28, 1], 12, 5, 1)\n",
    "relu1 = Relu(conv1.output_shape)\n",
    "pool1 = MaxPooling(relu1.output_shape)\n",
    "conv2 = Conv2D(pool1.output_shape, 24, 3, 1)\n",
    "relu2 = Relu(conv2.output_shape)\n",
    "pool2 = MaxPooling(relu2.output_shape)\n",
    "fc = FullyConnect(pool2.output_shape, 10)\n",
    "sf = Softmax(fc.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 / 20 [***************                                                                                         ] 141 / 937 ,loss:0.809692, acc:0.759198,remain=0:22:01"
     ]
    }
   ],
   "source": [
    "bar = ProgressBar(20, int(images.shape[0] / batch_size), \"loss:%f, acc:%f\")\n",
    "for epoch in range(1, 21):\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    batch_loss = 0\n",
    "    batch_acc = 0\n",
    "    val_acc = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    # train\n",
    "    train_acc = 0\n",
    "    train_loss = 0\n",
    "    for i in range(int(images.shape[0] / batch_size)):\n",
    "        img = images[i * batch_size:(i + 1) * batch_size].reshape([batch_size, 28, 28, 1])\n",
    "        label = labels[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "        conv1_out = conv1.forward(img)\n",
    "        relu1_out = relu1.forward(conv1_out)\n",
    "        pool1_out = pool1.forward(relu1_out)\n",
    "        conv2_out = conv2.forward(pool1_out)\n",
    "        relu2_out = relu2.forward(conv2_out)\n",
    "        pool2_out = pool2.forward(relu2_out)\n",
    "        fc_out = fc.forward(pool2_out)\n",
    "        batch_loss += sf.cal_loss(fc_out, np.array(label))\n",
    "        train_loss += sf.cal_loss(fc_out, np.array(label))\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            if np.argmax(sf.softmax[j]) == label[j]:\n",
    "                batch_acc += 1\n",
    "                train_acc += 1\n",
    "\n",
    "        sf.gradient()\n",
    "        conv1.gradient(relu1.gradient(pool1.gradient(\n",
    "            conv2.gradient(relu2.gradient(pool2.gradient(\n",
    "                fc.gradient(sf.eta)))))))\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            fc.backward(alpha=learning_rate, weight_decay=0.0004)\n",
    "            conv2.backward(alpha=learning_rate, weight_decay=0.0004)\n",
    "            conv1.backward(alpha=learning_rate, weight_decay=0.0004)\n",
    "\n",
    "        bar.show(epoch, batch_loss / (batch_size * (i + 1)), batch_acc / (batch_size * (i + 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitbaseconda57458418c2724739aed354b115ff2977",
   "language": "python",
   "display_name": "Python 3.6.9 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}