{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用条件对抗生成网络模拟图形\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as si\n",
    "import torch\n",
    "import os\n",
    "import numpy\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import JLib.utils as utils\n",
    "import jjzhk.imageutils  as iu\n",
    "import jjzhk.progressbar as bar\n",
    "\n",
    "z_dim = 2\n",
    "DIMENSION = 2\n",
    "iterations = 3000\n",
    "bs = 2000\n",
    "\n",
    "INPUT_IMAGE_PATH = \"inputs/vortex\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(DeepMLP, self).__init__()\n",
    "        self.map1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = torch.nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.LeakyReLU(negative_slope = 0.1)(self.map1(x))\n",
    "        x = torch.nn.LeakyReLU(negative_slope = 0.1)(self.map2(x))\n",
    "        return torch.nn.functional.sigmoid(self.map3(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [os.sep.join([INPUT_IMAGE_PATH, x]) for x in os.listdir(INPUT_IMAGE_PATH)]\n",
    "density_imgs = [si.imread(x, True) for x in image_paths]\n",
    "luts_2d = [epnu.generate_lut(x) for x in density_imgs]\n",
    "pix_sums = [numpy.sum(x) for x in density_imgs]\n",
    "total_pix_sums = numpy.sum(pix_sums)\n",
    "c_indices = [0] + [int(sum(pix_sums[:i+1])/total_pix_sums*bs+0.5) for i in range(len(pix_sums)-1)] + [bs]\n",
    "\n",
    "c_dim = len(luts_2d)    # Dimensionality of condition labels <--> number of images\n",
    "\n",
    "visualizer = utils.CGANDemoVisualizer('GAN 2D Example Visualization of {}'.format(INPUT_IMAGE_PATH))\n",
    "generator = DeepMLP(input_size=z_dim+c_dim, hidden_size=50, output_size=DIMENSION)\n",
    "discriminator = DeepMLP(input_size=DIMENSION+c_dim, hidden_size=100, output_size=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adadelta(discriminator.parameters(), lr=1)\n",
    "g_optimizer = torch.optim.Adadelta(generator.parameters(), lr=1)\n",
    "\n",
    "y = numpy.zeros((bs, c_dim))\n",
    "for i in range(c_dim):\n",
    "    y[c_indices[i]:c_indices[i + 1], i] = 1  # conditional labels, one-hot encoding\n",
    "y = torch.autograd.Variable(torch.Tensor(y))\n",
    "if torch.cuda.is_available():\n",
    "    y = y.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proBar = bar.ProgressBar(1, iterations, \"D Loss:(real/fake) %.3f/%.3f,G Loss:%.3f\")\n",
    "for train_iter in range(1, iterations + 1):\n",
    "    for d_index in range(3):\n",
    "        # 1. Train D on real+fake\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        real_samples = numpy.zeros((bs, DIMENSION))\n",
    "        for i in range(c_dim):\n",
    "            real_samples[c_indices[i]:c_indices[i+1], :] = epnu.sample_2d(luts_2d[i], c_indices[i+1]-c_indices[i])\n",
    "\n",
    "        # first c dimensions is the condition inputs, the last 2 dimensions are samples\n",
    "        real_samples = torch.autograd.Variable(torch.Tensor(real_samples))\n",
    "        if torch.cuda.is_available():\n",
    "            real_samples = real_samples.cuda()\n",
    "        d_real_data = torch.cat([y, real_samples], 1)\n",
    "        if torch.cuda.is_available():\n",
    "            d_real_data = d_real_data.cuda()\n",
    "\n",
    "        d_real_decision = discriminator(d_real_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        d_real_loss = criterion(d_real_decision, labels)  # ones = true\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        latent_samples = torch.autograd.Variable(torch.randn(bs, z_dim))\n",
    "        if torch.cuda.is_available():\n",
    "            latent_samples = latent_samples.cuda()\n",
    "\n",
    "        d_gen_input = torch.cat([y, latent_samples], 1)\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        conditional_d_fake_data = torch.cat([y, d_fake_data], 1)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            conditional_d_fake_data = conditional_d_fake_data.cuda()\n",
    "        d_fake_decision = discriminator(conditional_d_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.zeros(bs))\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.cuda()\n",
    "        d_fake_loss = criterion(d_fake_decision, labels)  # zeros = fake\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "\n",
    "    for g_index in range(1):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        generator.zero_grad()\n",
    "\n",
    "        latent_samples = torch.randn(bs, z_dim)\n",
    "        latent_samples = torch.autograd.Variable(latent_samples)\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            latent_samples = latent_samples.cuda()\n",
    "\n",
    "        g_gen_input = torch.cat([y, latent_samples], 1)\n",
    "        g_fake_data = generator(g_gen_input)\n",
    "        conditional_g_fake_data = torch.cat([y, g_fake_data], 1)\n",
    "        g_fake_decision = discriminator(conditional_g_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available():\n",
    "            labels = labels.cuda()\n",
    "        g_loss = criterion(g_fake_decision, labels)  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    loss_d_real = d_real_loss.item()\n",
    "    loss_d_fake = d_fake_loss.item()\n",
    "    loss_g = g_loss.item()\n",
    "\n",
    "    proBar.show(1, loss_d_real, loss_d_fake, loss_g)\n",
    "    if train_iter == 1 or train_iter % 100 == 0:\n",
    "        msg = 'Iteration {}: D_loss(real/fake): {:.6g}/{:.6g} G_loss: {:.6g}'.format(train_iter, loss_d_real, loss_d_fake, loss_g)\n",
    "\n",
    "        real_samples_with_y = d_real_data.data.cpu().numpy() if torch.cuda.is_available() else d_real_data.data.numpy()\n",
    "        gen_samples_with_y = conditional_g_fake_data.data.cpu().numpy() if torch.cuda.is_available() else conditional_g_fake_data.data.numpy()\n",
    "\n",
    "        visualizer.draw(real_samples_with_y, gen_samples_with_y, msg, show=False)\n",
    "        visualizer.savefig('outputs/Pytorch_Z_%04d' % train_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.生成动画"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker = iu.ImageToGif()\n",
    "maker.makeGif(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}