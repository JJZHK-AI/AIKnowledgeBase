{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用简单GAN模拟蝙蝠\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.简单模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as si\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import JLib.utils as utils\n",
    "import jjzhk.imageutils  as iu\n",
    "import jjzhk.progressbar as bar\n",
    "\n",
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.map1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.LeakyReLU(negative_slope = 0.1)(self.map1(x))\n",
    "        return torch.nn.functional.sigmoid(self.map2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.全局设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 972x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_dim = 2\n",
    "DIMENSION = 2\n",
    "iterations = 3000\n",
    "bs = 2000\n",
    "\n",
    "INPUT_IMAGE_PATH = \"inputs/batman.jpg\"\n",
    "density_img = si.imread(INPUT_IMAGE_PATH, True)\n",
    "lut_2d = utils.generate_lut(density_img)\n",
    "\n",
    "visualizer = utils.GANDemoVisualizer('GAN 2D Example Visualization of {}'.format(INPUT_IMAGE_PATH))\n",
    "generator = SimpleMLP(input_size=z_dim, hidden_size=50, output_size=DIMENSION)\n",
    "discriminator = SimpleMLP(input_size=DIMENSION, hidden_size=100, output_size=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adadelta(discriminator.parameters(), lr=1)\n",
    "g_optimizer = torch.optim.Adadelta(generator.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:1 / 1 [                                                                                                    ] 1 / 3000 ,D Loss:(real/fake) 0.684/0.705,G Loss:0.685,remain=0:32:23"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/usr/local/miniconda3/envs/dl/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([2000])) that is different to the input size (torch.Size([2000, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 / 1 [****************************************************************************************************] 3000 / 3000 ,D Loss:(real/fake) 0.692/0.694,G Loss:0.692,total=0:09:000\n"
     ]
    }
   ],
   "source": [
    "proBar = bar.ProgressBar(1, iterations, \"D Loss:(real/fake) %.3f/%.3f,G Loss:%.3f\")\n",
    "\n",
    "for train_iter in range(1, iterations + 1):\n",
    "    for d_index in range(3):\n",
    "        # 1. Train D on real+fake\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        real_samples = utils.sample_2d(lut_2d, bs)\n",
    "        d_real_data = torch.autograd.Variable(torch.Tensor(real_samples))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            d_real_data = d_real_data.cuda()\n",
    "        d_real_decision = discriminator(d_real_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        d_real_loss = criterion(d_real_decision, labels)  # ones = true\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        latent_samples = torch.randn(bs, z_dim)\n",
    "        d_gen_input = torch.autograd.Variable(latent_samples)\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            d_gen_input = d_gen_input.cuda()\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = discriminator(d_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.zeros(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        d_fake_loss = criterion(d_fake_decision, labels)  # zeros = fake\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(1):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        generator.zero_grad()\n",
    "\n",
    "        latent_samples = torch.randn(bs, z_dim)\n",
    "        g_gen_input = torch.autograd.Variable(latent_samples)\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            g_gen_input = g_gen_input.cuda()\n",
    "        g_fake_data = generator(g_gen_input)\n",
    "        g_fake_decision = discriminator(g_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        g_loss = criterion(g_fake_decision, labels)  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    loss_d_real = d_real_loss.item()\n",
    "    loss_d_fake = d_fake_loss.item()\n",
    "    loss_g = g_loss.item()\n",
    "\n",
    "    proBar.show(1, loss_d_real, loss_d_fake, loss_g)\n",
    "    if train_iter == 1 or train_iter % 100 == 0:\n",
    "        msg = 'Iteration {}: D_loss(real/fake): {:.6g}/{:.6g} G_loss: {:.6g}'.format(train_iter, loss_d_real, loss_d_fake, loss_g)\n",
    "\n",
    "        gen_samples = g_fake_data.data.cpu().numpy()\n",
    "\n",
    "        visualizer.draw(real_samples, gen_samples, msg, show=False)\n",
    "        visualizer.savefig('outputs/Pytorch_Batman_%04d' % train_iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.生成gif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker = iu.ImageToGif()\n",
    "maker(\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images](images/batman.gif)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}