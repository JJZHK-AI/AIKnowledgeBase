{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitanaconda3virtualenv5d618e8c7b894374a565943176146b80",
   "display_name": "Python 3.6.9 64-bit ('anaconda3': virtualenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Epoch:1 / 1 [****************************************************************************************************] 3000 / 3000 ,D Loss:(real/fake) 0.693/0.692,G Loss:0.695,total=0:07:57\n"
    },
    {
     "ename": "AttributeError",
     "evalue": "'ImageToGif' object has no attribute 'makeGif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-17eebc74e846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mmaker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageToGif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mmaker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeGif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageToGif' object has no attribute 'makeGif'"
     ]
    }
   ],
   "source": [
    "import skimage.io as si\n",
    "import JLib.utils as utils\n",
    "import torch\n",
    "import jjzhk.imageutils  as iu\n",
    "import jjzhk.progressbar as bar\n",
    "\n",
    "\n",
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.map1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = torch.nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.LeakyReLU(negative_slope = 0.1)(self.map1(x))\n",
    "        return torch.nn.functional.sigmoid(self.map2(x))\n",
    "\n",
    "z_dim = 2\n",
    "DIMENSION = 2\n",
    "iterations = 3000\n",
    "bs = 2000\n",
    "\n",
    "INPUT_IMAGE_PATH = \"inputs/batman.jpg\"\n",
    "density_img = si.imread(INPUT_IMAGE_PATH, True)\n",
    "lut_2d = utils.generate_lut(density_img)\n",
    "\n",
    "visualizer = utils.GANDemoVisualizer('GAN 2D Example Visualization of {}'.format(INPUT_IMAGE_PATH))\n",
    "generator = SimpleMLP(input_size=z_dim, hidden_size=50, output_size=DIMENSION)\n",
    "discriminator = SimpleMLP(input_size=DIMENSION, hidden_size=100, output_size=1)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = generator.cuda()\n",
    "    discriminator = discriminator.cuda()\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adadelta(discriminator.parameters(), lr=1)\n",
    "g_optimizer = torch.optim.Adadelta(generator.parameters(), lr=1)\n",
    "proBar = bar.ProgressBar(1, iterations, \"D Loss:(real/fake) %.3f/%.3f,G Loss:%.3f\")\n",
    "\n",
    "for train_iter in range(1, iterations + 1):\n",
    "    for d_index in range(3):\n",
    "        # 1. Train D on real+fake\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        #  1A: Train D on real\n",
    "        real_samples = utils.sample_2d(lut_2d, bs)\n",
    "        d_real_data = torch.autograd.Variable(torch.Tensor(real_samples))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            d_real_data = d_real_data.cuda()\n",
    "        d_real_decision = discriminator(d_real_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        d_real_loss = criterion(d_real_decision, labels)  # ones = true\n",
    "\n",
    "        #  1B: Train D on fake\n",
    "        latent_samples = torch.randn(bs, z_dim)\n",
    "        d_gen_input = torch.autograd.Variable(latent_samples)\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            d_gen_input = d_gen_input.cuda()\n",
    "        d_fake_data = generator(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "        d_fake_decision = discriminator(d_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.zeros(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        d_fake_loss = criterion(d_fake_decision, labels)  # zeros = fake\n",
    "\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "\n",
    "        d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "    for g_index in range(1):\n",
    "        # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "        generator.zero_grad()\n",
    "\n",
    "        latent_samples = torch.randn(bs, z_dim)\n",
    "        g_gen_input = torch.autograd.Variable(latent_samples)\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            g_gen_input = g_gen_input.cuda()\n",
    "        g_fake_data = generator(g_gen_input)\n",
    "        g_fake_decision = discriminator(g_fake_data)\n",
    "        labels = torch.autograd.Variable(torch.ones(bs))\n",
    "        if torch.cuda.is_available() > 0:\n",
    "            labels = labels.cuda()\n",
    "        g_loss = criterion(g_fake_decision, labels)  # we want to fool, so pretend it's all genuine\n",
    "\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()  # Only optimizes G's parameters\n",
    "\n",
    "    loss_d_real = d_real_loss.item()\n",
    "    loss_d_fake = d_fake_loss.item()\n",
    "    loss_g = g_loss.item()\n",
    "\n",
    "    proBar.show(1, loss_d_real, loss_d_fake, loss_g)\n",
    "    if train_iter == 1 or train_iter % 100 == 0:\n",
    "        msg = 'Iteration {}: D_loss(real/fake): {:.6g}/{:.6g} G_loss: {:.6g}'.format(train_iter, loss_d_real, loss_d_fake, loss_g)\n",
    "\n",
    "        gen_samples = g_fake_data.data.cpu().numpy()\n",
    "\n",
    "        visualizer.draw(real_samples, gen_samples, msg, show=False)\n",
    "        visualizer.savefig('outputs/Pytorch_Batman_%04d' % train_iter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maker = iu.ImageToGif()\n",
    "maker(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}