{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitbaseconda57458418c2724739aed354b115ff2977",
   "display_name": "Python 3.6.9 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "无约束凸优化问题求解\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.无约束凸优化问题\n",
    "我们知道，当$m=p=0$的时候，叫做无约束凸优化问题，那么$x^* \\in X$是可微函数$f$的最优解的充要条件是$\\nabla{f(x^*)}=0$。因此求解无约束凸优化问题等价于求解$n$个变量$x_1,x_2,...,x_n$的$n$个方程。对于少数一些简单的凸优化问题，可以利用最优性准则通过解析来求解。但对于大多数凸优化问题来讲，是没有办法通过解析来求解的。一般情况下，我们需要采用迭代法来求解。即计算点列$x^{(0)},x^{(1)},... \\in dom f$,是的$k \\rightarrow \\infty$时，$f(x^{(k)}) \\rightarrow p^*$,这样的点列称为优化问题的极小化点列"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.下降方法\n",
    "下降方法将产生一个优化点列$x^{(k)},k=1,...,$其中\n",
    "$$x^{(k+1)}=x^{(k)}+t^{(k)}\\Delta{x}^{(k)},t^{(k)}>0$$\n",
    "使得\n",
    "$$f(x^{(k+1)})<f(x^{(k)})$$\n",
    "$\\Delta{x}^{(k)}$被称为搜索方向，$t^{(k)}$被称为步长。由凸函数的一阶条件可知，下降方法中的搜索方向必须满足：\n",
    "$$\\nabla{f(x^{(k)})}^T\\Delta{x}^{(k)}<0$$\n",
    "即搜索方向和扶梯度方向的夹角必须是锐角"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "下降方法中，有两个问题需要解决：确定搜索步长和确定搜索方向。\n",
    "- 确定搜索步长的方法：固定步长搜索、精确直线搜索、回溯直线搜索\n",
    "- 确定搜索方向的方法：梯度下降法、最速下降法、牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "给定初始点$x \\in domf$，以下方法重复进行\n",
    "- 确定下降方向$\\Delta{x}$\n",
    "- 直线搜索，选择步长$t > 0$\n",
    "- 修改$x := x + t\\Delta{x}$\n",
    "\n",
    "直到满足停止准则"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1.确定步长的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1.1.固定步长搜索\n",
    "步长值根据经验设定，为了防止算法震荡，值应当较小。优点：直观、简单；缺点：收敛速度慢"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1.2.精确直线搜索\n",
    "搜索方向确定时，精确直线搜索步长沿着射线$\\{x+t\\Delta{x}|t \\geq 0\\}$，求解如下优化问题\n",
    "$$t=argmin_{s \\geq 0}f(x+s\\Delta{x})$$\n",
    "当其优化成本比较低时，适合精确直线搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.1.3.回溯直线搜索\n",
    "比较常用的是回溯直线搜索，大概思路是，用迭代方法求得的步长只要能使目标函数有足够的减少即可。可以参考[回溯直线搜索](04.无约束凸优化的解.02.回溯直线搜索.ipynb)的介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2.调整搜索方向"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.1.梯度下降法\n",
    "下降方法中必须满足，搜索方向和负梯度成锐角。用负梯度作为搜索方向就自然而然了，即\n",
    "$$\\Delta(x)=-\\nabla{f(x)}$$\n",
    "可以参考[梯度下降法](04.无约束凸优化的解.03.梯度下降法.ipynb)的介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.2.最速下降法\n",
    "利用目标函数的一阶泰勒展开近似优化过程，进而确定学习方向。可以参考[最速下降法](04.无约束凸优化的解.04.最速下降法.ipynb)的介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.2.3.牛顿法\n",
    "利用目标函数的二阶泰勒展开近似表示目标函数，通过求解这个二次函数的极小值来确定搜索方向.可以参考[牛顿法](04.无约束凸优化的解.05.牛顿法.ipynb)的介绍"
   ]
  }
 ]
}