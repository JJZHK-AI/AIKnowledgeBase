{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LeNet网络对QuickDraw进行分类\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.全局设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Architecture\n",
    "NUM_FEATURES = 28*28\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd1b6d2ddd8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "DATA_ROOT = os.path.join(\"/data/input/QuickDraw\")\n",
    "CSV_FILE = os.path.join(DATA_ROOT, \"quickdraw_png_set1_train.csv\")\n",
    "IMAGE_FILE = os.path.join(DATA_ROOT, \"images\")\n",
    "\n",
    "df = pd.read_csv(CSV_FILE, index_col=0)\n",
    "df.head()\n",
    "\n",
    "main_dir = IMAGE_FILE\n",
    "\n",
    "img = Image.open(os.path.join(main_dir, df.index[99]))\n",
    "img = np.asarray(img, dtype=np.uint8)\n",
    "print(img.shape)\n",
    "plt.imshow(np.array(img), cmap='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.自定义数据集并导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuickdrawDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for loading Quickdraw images\"\"\"\n",
    "\n",
    "    def __init__(self, txt_path, img_dir, transform=None):\n",
    "    \n",
    "        df = pd.read_csv(txt_path, sep=\",\", index_col=0)\n",
    "        self.img_dir = img_dir\n",
    "        self.txt_path = txt_path\n",
    "        self.img_names = df.index.values\n",
    "        self.y = df['Label'].values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(os.path.join(self.img_dir,\n",
    "                                      self.img_names[index]))\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.y[index]\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "custom_transform = transforms.Compose([#transforms.Lambda(lambda x: x/255.),\n",
    "                                       transforms.ToTensor()])\n",
    "\n",
    "train_dataset = QuickdrawDataset(txt_path=CSV_FILE,\n",
    "                                 img_dir=IMAGE_FILE,\n",
    "                                 transform=custom_transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4) \n",
    "\n",
    "\n",
    "valid_dataset = QuickdrawDataset(txt_path=CSV_FILE,\n",
    "                                img_dir=IMAGE_FILE,\n",
    "                                transform=custom_transform)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=False,\n",
    "                          num_workers=4) \n",
    "\n",
    "\n",
    "\n",
    "test_dataset = QuickdrawDataset(txt_path=CSV_FILE,\n",
    "                                img_dir=IMAGE_FILE,\n",
    "                                transform=custom_transform)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, grayscale=False):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.grayscale = grayscale\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if self.grayscale:\n",
    "            in_channels = 1\n",
    "        else:\n",
    "            in_channels = 3\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(in_channels, 6, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*4*4, 120),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(84, num_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        logits = self.classifier(x)\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(NUM_CLASSES, GRAYSCALE)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sizes(self, input, output):\n",
    "\n",
    "    print('Inside ' + self.__class__.__name__ + ' forward')\n",
    "    print('input size:', input[0].size())\n",
    "    print('output size:', output.data.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 0000/8290 | Cost: 0.2126\n",
      "Epoch: 001/010 | Batch 0500/8290 | Cost: 0.1876\n",
      "Epoch: 001/010 | Batch 1000/8290 | Cost: 0.4302\n",
      "Epoch: 001/010 | Batch 1500/8290 | Cost: 0.3281\n",
      "Epoch: 001/010 | Batch 2000/8290 | Cost: 0.4043\n",
      "Epoch: 001/010 | Batch 2500/8290 | Cost: 0.3368\n",
      "Epoch: 001/010 | Batch 3000/8290 | Cost: 0.2820\n",
      "Epoch: 001/010 | Batch 3500/8290 | Cost: 0.3836\n",
      "Epoch: 001/010 | Batch 4000/8290 | Cost: 0.3124\n",
      "Epoch: 001/010 | Batch 4500/8290 | Cost: 0.2804\n",
      "Epoch: 001/010 | Batch 5000/8290 | Cost: 0.2947\n",
      "Epoch: 001/010 | Batch 5500/8290 | Cost: 0.4019\n",
      "Epoch: 001/010 | Batch 6000/8290 | Cost: 0.2704\n",
      "Epoch: 001/010 | Batch 6500/8290 | Cost: 0.1082\n",
      "Epoch: 001/010 | Batch 7000/8290 | Cost: 0.5216\n",
      "Epoch: 001/010 | Batch 7500/8290 | Cost: 0.2195\n",
      "Epoch: 001/010 | Batch 8000/8290 | Cost: 0.3900\n",
      "Epoch: 001/010 | Train: 91.604% | Validation: 91.604%\n",
      "Time elapsed: 13.51 min\n",
      "Epoch: 002/010 | Batch 0000/8290 | Cost: 0.2495\n",
      "Epoch: 002/010 | Batch 0500/8290 | Cost: 0.1959\n",
      "Epoch: 002/010 | Batch 1000/8290 | Cost: 0.2316\n",
      "Epoch: 002/010 | Batch 1500/8290 | Cost: 0.3806\n",
      "Epoch: 002/010 | Batch 2000/8290 | Cost: 0.2843\n",
      "Epoch: 002/010 | Batch 2500/8290 | Cost: 0.2734\n",
      "Epoch: 002/010 | Batch 3000/8290 | Cost: 0.2968\n",
      "Epoch: 002/010 | Batch 3500/8290 | Cost: 0.1849\n",
      "Epoch: 002/010 | Batch 4000/8290 | Cost: 0.3123\n",
      "Epoch: 002/010 | Batch 4500/8290 | Cost: 0.1712\n",
      "Epoch: 002/010 | Batch 5000/8290 | Cost: 0.2927\n",
      "Epoch: 002/010 | Batch 5500/8290 | Cost: 0.2264\n",
      "Epoch: 002/010 | Batch 6000/8290 | Cost: 0.2927\n",
      "Epoch: 002/010 | Batch 6500/8290 | Cost: 0.1565\n",
      "Epoch: 002/010 | Batch 7000/8290 | Cost: 0.1775\n",
      "Epoch: 002/010 | Batch 7500/8290 | Cost: 0.2679\n",
      "Epoch: 002/010 | Batch 8000/8290 | Cost: 0.2079\n",
      "Epoch: 002/010 | Train: 91.784% | Validation: 91.784%\n",
      "Time elapsed: 26.66 min\n",
      "Epoch: 003/010 | Batch 0000/8290 | Cost: 0.2186\n",
      "Epoch: 003/010 | Batch 0500/8290 | Cost: 0.2415\n",
      "Epoch: 003/010 | Batch 1000/8290 | Cost: 0.1566\n",
      "Epoch: 003/010 | Batch 1500/8290 | Cost: 0.1808\n",
      "Epoch: 003/010 | Batch 2000/8290 | Cost: 0.3652\n",
      "Epoch: 003/010 | Batch 2500/8290 | Cost: 0.1792\n",
      "Epoch: 003/010 | Batch 3000/8290 | Cost: 0.1284\n",
      "Epoch: 003/010 | Batch 3500/8290 | Cost: 0.3296\n",
      "Epoch: 003/010 | Batch 4000/8290 | Cost: 0.2569\n",
      "Epoch: 003/010 | Batch 4500/8290 | Cost: 0.2261\n",
      "Epoch: 003/010 | Batch 5000/8290 | Cost: 0.2765\n",
      "Epoch: 003/010 | Batch 5500/8290 | Cost: 0.3293\n",
      "Epoch: 003/010 | Batch 6000/8290 | Cost: 0.1897\n",
      "Epoch: 003/010 | Batch 6500/8290 | Cost: 0.2774\n",
      "Epoch: 003/010 | Batch 7000/8290 | Cost: 0.1759\n",
      "Epoch: 003/010 | Batch 7500/8290 | Cost: 0.3996\n",
      "Epoch: 003/010 | Batch 8000/8290 | Cost: 0.2506\n",
      "Epoch: 003/010 | Train: 92.356% | Validation: 92.356%\n",
      "Time elapsed: 38.96 min\n",
      "Epoch: 004/010 | Batch 0000/8290 | Cost: 0.1850\n",
      "Epoch: 004/010 | Batch 0500/8290 | Cost: 0.3075\n",
      "Epoch: 004/010 | Batch 1000/8290 | Cost: 0.3363\n",
      "Epoch: 004/010 | Batch 1500/8290 | Cost: 0.2238\n",
      "Epoch: 004/010 | Batch 2000/8290 | Cost: 0.2927\n",
      "Epoch: 004/010 | Batch 2500/8290 | Cost: 0.2793\n",
      "Epoch: 004/010 | Batch 3000/8290 | Cost: 0.3107\n",
      "Epoch: 004/010 | Batch 3500/8290 | Cost: 0.2853\n",
      "Epoch: 004/010 | Batch 4000/8290 | Cost: 0.2914\n",
      "Epoch: 004/010 | Batch 4500/8290 | Cost: 0.3399\n",
      "Epoch: 004/010 | Batch 5000/8290 | Cost: 0.2839\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ae54621d8c53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 500:\n",
    "            print ('Epoch: %03d/%03d | Batch %04d/%04d | Cost: %.4f' \n",
    "                   %(epoch+1, NUM_EPOCHS, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.set_grad_enabled(False): # save memory during inference\n",
    "        print('Epoch: %03d/%03d | Train: %.3f%% | Validation: %.3f%%' % (\n",
    "              epoch+1, NUM_EPOCHS, \n",
    "              compute_accuracy(model, train_loader, device=DEVICE),\n",
    "              compute_accuracy(model, valid_loader, device=DEVICE) ))\n",
    "        \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
