{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用Kaiming方法进行权重初始化的卷积神经网络\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebastian Raschka \n",
      "\n",
      "CPython 3.6.9\n",
      "IPython 7.9.0\n",
      "\n",
      "torch 1.1.0\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Sebastian Raschka' -v -p torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.05\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='/data/input', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='/data/input', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        # calculate same padding:\n",
    "        # (w - k + 2*p)/s + 1 = o\n",
    "        # => p = (s(o-1) - w + k)/2\n",
    "        \n",
    "        # 28x28x1 => 28x28x4\n",
    "        self.conv_1 = torch.nn.Conv2d(in_channels=1,\n",
    "                                      out_channels=4,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1) # (1(28-1) - 28 + 3) / 2 = 1\n",
    "        # 28x28x4 => 14x14x4\n",
    "        self.pool_1 = torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                         stride=(2, 2),\n",
    "                                         padding=0) # (2(14-1) - 28 + 2) = 0                                       \n",
    "        # 14x14x4 => 14x14x8\n",
    "        self.conv_2 = torch.nn.Conv2d(in_channels=4,\n",
    "                                      out_channels=8,\n",
    "                                      kernel_size=(3, 3),\n",
    "                                      stride=(1, 1),\n",
    "                                      padding=1) # (1(14-1) - 14 + 3) / 2 = 1                 \n",
    "        # 14x14x8 => 7x7x8                             \n",
    "        self.pool_2 = torch.nn.MaxPool2d(kernel_size=(2, 2),\n",
    "                                         stride=(2, 2),\n",
    "                                         padding=0) # (2(7-1) - 14 + 2) = 0\n",
    "        \n",
    "        self.linear_1 = torch.nn.Linear(7*7*8, num_classes)\n",
    "        \n",
    "        ###############################################\n",
    "        # Reinitialize weights using He initialization\n",
    "        ###############################################\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.detach())\n",
    "                m.bias.detach().zero_()\n",
    "            elif isinstance(m, torch.nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight.detach())\n",
    "                m.bias.detach().zero_()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv_1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool_1(out)\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool_2(out)\n",
    "        \n",
    "        logits = self.linear_1(out.view(-1, 7*7*8))\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes=num_classes)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/469 | Cost: 2.4577\n",
      "Epoch: 001/010 | Batch 050/469 | Cost: 1.1068\n",
      "Epoch: 001/010 | Batch 100/469 | Cost: 0.6609\n",
      "Epoch: 001/010 | Batch 150/469 | Cost: 0.5353\n",
      "Epoch: 001/010 | Batch 200/469 | Cost: 0.4480\n",
      "Epoch: 001/010 | Batch 250/469 | Cost: 0.3158\n",
      "Epoch: 001/010 | Batch 300/469 | Cost: 0.4544\n",
      "Epoch: 001/010 | Batch 350/469 | Cost: 0.4276\n",
      "Epoch: 001/010 | Batch 400/469 | Cost: 0.1386\n",
      "Epoch: 001/010 | Batch 450/469 | Cost: 0.1409\n",
      "Epoch: 001/010 training accuracy: 91.96%\n",
      "Time elapsed: 0.19 min\n",
      "Epoch: 002/010 | Batch 000/469 | Cost: 0.2197\n",
      "Epoch: 002/010 | Batch 050/469 | Cost: 0.1464\n",
      "Epoch: 002/010 | Batch 100/469 | Cost: 0.2628\n",
      "Epoch: 002/010 | Batch 150/469 | Cost: 0.1918\n",
      "Epoch: 002/010 | Batch 200/469 | Cost: 0.1487\n",
      "Epoch: 002/010 | Batch 250/469 | Cost: 0.1230\n",
      "Epoch: 002/010 | Batch 300/469 | Cost: 0.1591\n",
      "Epoch: 002/010 | Batch 350/469 | Cost: 0.1412\n",
      "Epoch: 002/010 | Batch 400/469 | Cost: 0.1403\n",
      "Epoch: 002/010 | Batch 450/469 | Cost: 0.1211\n",
      "Epoch: 002/010 training accuracy: 95.22%\n",
      "Time elapsed: 0.36 min\n",
      "Epoch: 003/010 | Batch 000/469 | Cost: 0.1289\n",
      "Epoch: 003/010 | Batch 050/469 | Cost: 0.2473\n",
      "Epoch: 003/010 | Batch 100/469 | Cost: 0.1310\n",
      "Epoch: 003/010 | Batch 150/469 | Cost: 0.1890\n",
      "Epoch: 003/010 | Batch 200/469 | Cost: 0.1053\n",
      "Epoch: 003/010 | Batch 250/469 | Cost: 0.1566\n",
      "Epoch: 003/010 | Batch 300/469 | Cost: 0.1234\n",
      "Epoch: 003/010 | Batch 350/469 | Cost: 0.1388\n",
      "Epoch: 003/010 | Batch 400/469 | Cost: 0.1557\n",
      "Epoch: 003/010 | Batch 450/469 | Cost: 0.1657\n",
      "Epoch: 003/010 training accuracy: 96.45%\n",
      "Time elapsed: 0.53 min\n",
      "Epoch: 004/010 | Batch 000/469 | Cost: 0.1828\n",
      "Epoch: 004/010 | Batch 050/469 | Cost: 0.0612\n",
      "Epoch: 004/010 | Batch 100/469 | Cost: 0.1967\n",
      "Epoch: 004/010 | Batch 150/469 | Cost: 0.1072\n",
      "Epoch: 004/010 | Batch 200/469 | Cost: 0.1062\n",
      "Epoch: 004/010 | Batch 250/469 | Cost: 0.0968\n",
      "Epoch: 004/010 | Batch 300/469 | Cost: 0.0594\n",
      "Epoch: 004/010 | Batch 350/469 | Cost: 0.1033\n",
      "Epoch: 004/010 | Batch 400/469 | Cost: 0.1504\n",
      "Epoch: 004/010 | Batch 450/469 | Cost: 0.1620\n",
      "Epoch: 004/010 training accuracy: 96.61%\n",
      "Time elapsed: 0.71 min\n",
      "Epoch: 005/010 | Batch 000/469 | Cost: 0.0471\n",
      "Epoch: 005/010 | Batch 050/469 | Cost: 0.0350\n",
      "Epoch: 005/010 | Batch 100/469 | Cost: 0.1233\n",
      "Epoch: 005/010 | Batch 150/469 | Cost: 0.0434\n",
      "Epoch: 005/010 | Batch 200/469 | Cost: 0.1049\n",
      "Epoch: 005/010 | Batch 250/469 | Cost: 0.1133\n",
      "Epoch: 005/010 | Batch 300/469 | Cost: 0.2231\n",
      "Epoch: 005/010 | Batch 350/469 | Cost: 0.1272\n",
      "Epoch: 005/010 | Batch 400/469 | Cost: 0.1406\n",
      "Epoch: 005/010 | Batch 450/469 | Cost: 0.0642\n",
      "Epoch: 005/010 training accuracy: 97.22%\n",
      "Time elapsed: 0.89 min\n",
      "Epoch: 006/010 | Batch 000/469 | Cost: 0.0886\n",
      "Epoch: 006/010 | Batch 050/469 | Cost: 0.1365\n",
      "Epoch: 006/010 | Batch 100/469 | Cost: 0.1085\n",
      "Epoch: 006/010 | Batch 150/469 | Cost: 0.0794\n",
      "Epoch: 006/010 | Batch 200/469 | Cost: 0.0817\n",
      "Epoch: 006/010 | Batch 250/469 | Cost: 0.1878\n",
      "Epoch: 006/010 | Batch 300/469 | Cost: 0.1790\n",
      "Epoch: 006/010 | Batch 350/469 | Cost: 0.1110\n",
      "Epoch: 006/010 | Batch 400/469 | Cost: 0.1056\n",
      "Epoch: 006/010 | Batch 450/469 | Cost: 0.0736\n",
      "Epoch: 006/010 training accuracy: 97.22%\n",
      "Time elapsed: 1.07 min\n",
      "Epoch: 007/010 | Batch 000/469 | Cost: 0.1303\n",
      "Epoch: 007/010 | Batch 050/469 | Cost: 0.0941\n",
      "Epoch: 007/010 | Batch 100/469 | Cost: 0.0868\n",
      "Epoch: 007/010 | Batch 150/469 | Cost: 0.1713\n",
      "Epoch: 007/010 | Batch 200/469 | Cost: 0.0845\n",
      "Epoch: 007/010 | Batch 250/469 | Cost: 0.0878\n",
      "Epoch: 007/010 | Batch 300/469 | Cost: 0.0568\n",
      "Epoch: 007/010 | Batch 350/469 | Cost: 0.0804\n",
      "Epoch: 007/010 | Batch 400/469 | Cost: 0.0782\n",
      "Epoch: 007/010 | Batch 450/469 | Cost: 0.1235\n",
      "Epoch: 007/010 training accuracy: 97.48%\n",
      "Time elapsed: 1.24 min\n",
      "Epoch: 008/010 | Batch 000/469 | Cost: 0.0738\n",
      "Epoch: 008/010 | Batch 050/469 | Cost: 0.0673\n",
      "Epoch: 008/010 | Batch 100/469 | Cost: 0.1880\n",
      "Epoch: 008/010 | Batch 150/469 | Cost: 0.0759\n",
      "Epoch: 008/010 | Batch 200/469 | Cost: 0.0633\n",
      "Epoch: 008/010 | Batch 250/469 | Cost: 0.1165\n",
      "Epoch: 008/010 | Batch 300/469 | Cost: 0.0310\n",
      "Epoch: 008/010 | Batch 350/469 | Cost: 0.0822\n",
      "Epoch: 008/010 | Batch 400/469 | Cost: 0.1262\n",
      "Epoch: 008/010 | Batch 450/469 | Cost: 0.0488\n",
      "Epoch: 008/010 training accuracy: 97.53%\n",
      "Time elapsed: 1.42 min\n",
      "Epoch: 009/010 | Batch 000/469 | Cost: 0.0538\n",
      "Epoch: 009/010 | Batch 050/469 | Cost: 0.1864\n",
      "Epoch: 009/010 | Batch 100/469 | Cost: 0.0639\n",
      "Epoch: 009/010 | Batch 150/469 | Cost: 0.0393\n",
      "Epoch: 009/010 | Batch 200/469 | Cost: 0.0663\n",
      "Epoch: 009/010 | Batch 250/469 | Cost: 0.0878\n",
      "Epoch: 009/010 | Batch 300/469 | Cost: 0.1963\n",
      "Epoch: 009/010 | Batch 350/469 | Cost: 0.0718\n",
      "Epoch: 009/010 | Batch 400/469 | Cost: 0.0790\n",
      "Epoch: 009/010 | Batch 450/469 | Cost: 0.0225\n",
      "Epoch: 009/010 training accuracy: 97.89%\n",
      "Time elapsed: 1.60 min\n",
      "Epoch: 010/010 | Batch 000/469 | Cost: 0.0984\n",
      "Epoch: 010/010 | Batch 050/469 | Cost: 0.0770\n",
      "Epoch: 010/010 | Batch 100/469 | Cost: 0.1974\n",
      "Epoch: 010/010 | Batch 150/469 | Cost: 0.0394\n",
      "Epoch: 010/010 | Batch 200/469 | Cost: 0.0345\n",
      "Epoch: 010/010 | Batch 250/469 | Cost: 0.0538\n",
      "Epoch: 010/010 | Batch 300/469 | Cost: 0.1163\n",
      "Epoch: 010/010 | Batch 350/469 | Cost: 0.1022\n",
      "Epoch: 010/010 | Batch 400/469 | Cost: 0.1562\n",
      "Epoch: 010/010 | Batch 450/469 | Cost: 0.1758\n",
      "Epoch: 010/010 training accuracy: 97.79%\n",
      "Time elapsed: 1.77 min\n",
      "Total Training Time: 1.77 min\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model, data_loader):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for features, targets in data_loader:\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(num_epochs):\n",
    "    model = model.train()\n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "        \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 50:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))\n",
    "    \n",
    "    model = model.eval()\n",
    "    print('Epoch: %03d/%03d training accuracy: %.2f%%' % (\n",
    "          epoch+1, num_epochs, \n",
    "          compute_accuracy(model, train_loader)))\n",
    "    \n",
    "    print('Time elapsed: %.2f min' % ((time.time() - start_time)/60))\n",
    "    \n",
    "print('Total Training Time: %.2f min' % ((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: %.2f%%' % (compute_accuracy(model, test_loader)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
