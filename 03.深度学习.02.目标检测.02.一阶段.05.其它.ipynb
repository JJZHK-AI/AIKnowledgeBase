{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "RFB，FSSD，RetinaNet，FCN\n",
    "# 4.Focal Loss与RetinateNet\n",
    "YOLO的精度不够高，这是因为它做的是稠密分类，核心问题是稠密proposal中前景和背景的极度不平衡。比如PASCAL VOC数据集中，每张图片上标注的目标可能也就几个，但是YOLO V2最后一层的输出是13*13*5,也就是845个候选目标，大量的负样本在loss中占据了很大比重，使得有用的loss不能回传回来。基于此，作者将经典的交叉熵损失做了变形，给那些易于被分类的简单例子小的权重，给不易区分的难例更大的权重。同时，作者提出了一个新的one-stage的检测器RetinaNet，达到了速度和精度很好地trade-off。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.1.交叉熵损失\n",
    "Focal Loss从交叉熵损失而来，二分类的交叉熵损失如下:\n",
    "$$CE(p,y)=\\begin{cases}\n",
    "-log(p) & y=1\\\\\n",
    "-log(1-p) & otherwise\n",
    "\\end{cases}$$\n",
    "对应的，多分类的交叉熵损失是这样的：\n",
    "$$CE(p,y)=-log(p_y)$$\n",
    "![images](../Results/01/02_02_01_004.png)<br/>\n",
    "如上图所示，蓝色线为交叉熵损失函数随着pt变化的曲线(pt意为ground truth，是标注类别所对应的概率)。可以看到，当概率大于.5，即认为是易分类的简单样本时，值仍然较大。这样，很多简单样本累加起来，就很可能盖住那些稀少的不易正确分类的类别"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.2.Focal Loss损失\n",
    "为了改善类别样本分布不均衡的问题，已经有人提出了使用加上权重的交叉熵损失：\n",
    "$$CE(p)=-\\alpha_tlog(p_t)$$\n",
    "即用参数$\\alpha_t$来平衡，这组参数可以是超参数，也可以由类别的比例倒数决定。作者将其作为比较的baseline，提出了一个自适应调节的权重，即Focal Loss，定义如下：\n",
    "$$FL(p_t)=-(1-p_t)^{\\gamma}log(p_t)$$\n",
    "在实际实验中，作者使用的是加权之后的Focal Loss，作者发现这样能够带来些微的性能提升。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "def one_hot(index, classes):\n",
    "    size = index.size() + (classes,)\n",
    "    view = index.size() + (1,)\n",
    "    mask = torch.Tensor(*size).fill_(0)\n",
    "    index = index.view(*view)\n",
    "    ones = 1.\n",
    "    if isinstance(index, Variable):\n",
    "        ones = Variable(torch.Tensor(index.size()).fill_(1))\n",
    "        mask = Variable(mask, volatile=index.volatile)\n",
    "    return mask.scatter_(1, index, ones)\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, eps=1e-7):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = eps\n",
    "    def forward(self, input, target):\n",
    "        y = one_hot(target, input.size(-1))\n",
    "        logit = F.softmax(input)\n",
    "        logit = logit.clamp(self.eps, 1. - self.eps)\n",
    "        loss = -1 * y * torch.log(logit) # cross entropy\n",
    "        loss = loss * (1 - logit) ** self.gamma # focal loss\n",
    "        return loss.sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4.3.RetinaNet\n",
    "利用Focal Loss，基于ResNet和Feature Pyramid Net(FPN)设计了一种新的one-stage检测框架，命名为RetinaNet\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}