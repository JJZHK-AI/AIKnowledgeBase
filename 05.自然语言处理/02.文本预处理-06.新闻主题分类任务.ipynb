{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新闻主题分类任务\n",
    "==="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以一段新闻报道中的文本描述内容为输入，使用模型帮助我们判断他最优可能属于哪一种类型的新闻，这是典型的文本分类内容，我们这里假设每种类型是互斥的，即文本描述有且只有一种类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ag_news_csv.tar.gz: 11.8MB [00:01, 8.07MB/s]\n",
      "120000lines [00:04, 25903.66lines/s]\n",
      "120000lines [00:08, 14700.93lines/s]\n",
      "7600lines [00:00, 13262.97lines/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchtext.datasets import text_classification\n",
    "\n",
    "load_data_path = \"./data\"\n",
    "if not os.path.isdir(load_data_path):\n",
    "    os.mkdir(load_data_path)\n",
    "\n",
    "train_dataset, test_dataset = text_classification.DATASETS['AG_NEWS'](root=load_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3</th>\n      <th>Wall St. Bears Claw Back Into the Black (Reuters)</th>\n      <th>Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n      <td>Reuters - Private investment firm Carlyle Grou...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n      <td>Reuters - Authorities have halted oil export\\f...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Oil prices soar to all-time record, posing new...</td>\n      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>Stocks End Up, But Near Year Lows (Reuters)</td>\n      <td>Reuters - Stocks ended slightly higher on Frid...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>Money Funds Fell in Latest Week (AP)</td>\n      <td>AP - Assets of the nation's retail money marke...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>Fed minutes show dissent over inflation (USATO...</td>\n      <td>USATODAY.com - Retail sales bounced back a bit...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>Safety Net (Forbes.com)</td>\n      <td>Forbes.com - After earning a PH.D. in Sociolog...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>Wall St. Bears Claw Back Into the Black</td>\n      <td>NEW YORK (Reuters) - Short-sellers, Wall Stre...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3</td>\n      <td>Oil and Economy Cloud Stocks' Outlook</td>\n      <td>NEW YORK (Reuters) - Soaring crude prices plu...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   3  ... Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n0  3  ...  Reuters - Private investment firm Carlyle Grou...                                            \n1  3  ...  Reuters - Soaring crude prices plus worries\\ab...                                            \n2  3  ...  Reuters - Authorities have halted oil export\\f...                                            \n3  3  ...  AFP - Tearaway world oil prices, toppling reco...                                            \n4  3  ...  Reuters - Stocks ended slightly higher on Frid...                                            \n5  3  ...  AP - Assets of the nation's retail money marke...                                            \n6  3  ...  USATODAY.com - Retail sales bounced back a bit...                                            \n7  3  ...  Forbes.com - After earning a PH.D. in Sociolog...                                            \n8  3  ...   NEW YORK (Reuters) - Short-sellers, Wall Stre...                                            \n9  3  ...   NEW YORK (Reuters) - Soaring crude prices plu...                                            \n\n[10 rows x 3 columns]"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ROOT_PATH = os.path.join(load_data_path, 'ag_news_csv')\n",
    "train_data = pd.read_csv(os.path.join(ROOT_PATH, 'train.csv'))\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>3</th>\n      <th>Fears for T N pension after talks</th>\n      <th>Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>The Race is On: Second Private Team Sets Launc...</td>\n      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n      <td>AP - A company founded by a chemistry research...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n      <td>AP - Southern California's smog-fighting agenc...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Open Letter Against British Copyright Indoctri...</td>\n      <td>The British Department for Education and Skill...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>4</td>\n      <td>Loosing the War on Terrorism</td>\n      <td>\\\\\"Sven Jaschan, self-confessed author of the ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4</td>\n      <td>FOAFKey: FOAF, PGP, Key Distribution, and Bloo...</td>\n      <td>\\\\FOAF/LOAF  and bloom filters have a lot of i...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>E-mail scam targets police chief</td>\n      <td>Wiltshire Police warns about \"phishing\" after ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>Card fraud unit nets 36,000 cards</td>\n      <td>In its first two years, the UK's dedicated car...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4</td>\n      <td>Group to Propose New High-Speed Wireless Format</td>\n      <td>LOS ANGELES (Reuters) - A group of technology...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   3  ... Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\n0  4  ...  SPACE.com - TORONTO, Canada -- A second\\team o...                                                                             \n1  4  ...  AP - A company founded by a chemistry research...                                                                             \n2  4  ...  AP - It's barely dawn when Mike Fitzpatrick st...                                                                             \n3  4  ...  AP - Southern California's smog-fighting agenc...                                                                             \n4  4  ...  The British Department for Education and Skill...                                                                             \n5  4  ...  \\\\\"Sven Jaschan, self-confessed author of the ...                                                                             \n6  4  ...  \\\\FOAF/LOAF  and bloom filters have a lot of i...                                                                             \n7  4  ...  Wiltshire Police warns about \"phishing\" after ...                                                                             \n8  4  ...  In its first two years, the UK's dedicated car...                                                                             \n9  4  ...   LOS ANGELES (Reuters) - A group of technology...                                                                             \n\n[10 rows x 3 columns]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(os.path.join(ROOT_PATH, 'test.csv'))\n",
    "test_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.网络设计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1.构建带有Embedding层的文本分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from jjzhk import device\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSentiment(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, sparse=True)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        c = embedded.size(0) // BATCH_SIZE\n",
    "        embedded_ex = embedded[:BATCH_SIZE * c]\n",
    "        embedded_ex = embedded_ex.transpose(1, 0).unsqueeze(0)\n",
    "        embedded_ex = F.avg_pool1d(embedded_ex, kernel_size=c)\n",
    "        embedded_ex = embedded_ex[0].transpose(1, 0)\n",
    "        embedded_ex = self.fc(embedded_ex)\n",
    "        return embedded_ex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(train_dataset.get_vocab())\n",
    "EMBED_DIM = 32\n",
    "NUM_CLASS = len(train_dataset.get_labels())\n",
    "model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUM_CLASS).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2.对数据进行batch处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    text =[entry[1] for entry in batch]\n",
    "    text = torch.cat(text)\n",
    "    return text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 3, 32,  2,  8,  3, 45, 21,  6]), tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "batch = [(1, torch.tensor([3, 32, 2, 8])), (0, torch.tensor([3, 45, 21, 6]))]\n",
    "res = generate_batch(batch)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3.构建训练与验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "from torch.utils.data.dataset import random_split\n",
    "from jjzhk.progressbar import ProgressBar\n",
    "\n",
    "\n",
    "N_EPOCHS = 10\n",
    "min_valid_loss = float('inf')\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "train_len = int(len(train_dataset) * 0.95)\n",
    "sub_train_, sub_valid_ = random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "train_data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=generate_batch)\n",
    "valid_data = DataLoader(sub_valid_, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n",
    "bar_train = ProgressBar(N_EPOCHS, len(train_data), \"loss:%.3f;acc:%.3f\")\n",
    "bar_test = ProgressBar(1, len(valid_data), \"loss:%.3f;acc:%.3f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4.进行模型训练和验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.059;acc:0.644,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.709,total=0:00:00\n",
      "Epoch:2 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.052;acc:0.700,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.717,total=0:00:00\n",
      "Epoch:3 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.051;acc:0.711,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.706,total=0:00:00\n",
      "Epoch:4 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.050;acc:0.717,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.717,total=0:00:00\n",
      "Epoch:5 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.049;acc:0.720,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.709,total=0:00:00\n",
      "Epoch:6 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.048;acc:0.727,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.723,total=0:00:00\n",
      "Epoch:7 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.048;acc:0.729,total=0:00:22\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.728,total=0:00:00\n",
      "Epoch:8 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.048;acc:0.731,total=0:00:21\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.726,total=0:00:00\n",
      "Epoch:9 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.047;acc:0.733,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.723,total=0:00:00\n",
      "Epoch:10 / 10 [****************************************************************************************************] 7125 / 7125 ,loss:0.047;acc:0.736,total=0:00:19\n",
      "Epoch:1 / 1 [*****************************************************************************************************************************] 375 / 375 ,loss:0.000;acc:0.729,total=0:00:00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for i, (text, label) in enumerate(train_data):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(text)\n",
    "        loss = criterion(output, label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == label).sum().item()\n",
    "        bar_train.show(epoch + 1, train_loss / (BATCH_SIZE * (i + 1)), train_acc / (BATCH_SIZE * (i + 1)))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    for i, (text, label) in enumerate(valid_data):\n",
    "        with torch.no_grad():\n",
    "            output = model(text)\n",
    "            loss = criterion(output, label)\n",
    "            loss += loss.item()\n",
    "            acc += (output.argmax(1) == label).sum().item()\n",
    "        bar_test.show(1, loss / (BATCH_SIZE * (i + 1)), acc / (BATCH_SIZE * (i + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5.查看embedding层迁入的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1924,  0.4844,  0.0672,  ..., -0.3984, -0.0840, -0.0872],\n",
      "        [-0.0263, -0.2393,  0.0808,  ...,  0.4940,  0.0689, -0.4583],\n",
      "        [-0.1608, -0.0168, -0.0021,  ...,  0.1455, -0.0015, -0.0460],\n",
      "        ...,\n",
      "        [ 0.1416,  0.3386, -0.0076,  ..., -0.3229, -0.2432, -0.1422],\n",
      "        [-0.3922, -0.0447,  0.0746,  ..., -0.0954,  0.0334, -0.2103],\n",
      "        [ 0.3947, -0.4426,  0.4626,  ...,  0.1671, -0.1298, -0.2242]])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict()['embedding.weight'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python385jvsc74a57bd0962ff1a08bbd29f414ba67199d725d5b08f35603471a3d6cc67d6569664ed27c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}