{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用NetworkInNetwork对Cifar10进行分类\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.全局设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 1\n",
    "LEARNING_RATE = 0.0005\n",
    "BATCH_SIZE = 256\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = \"cuda:0\"\n",
    "GRAYSCALE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_indices = torch.arange(0, 49000)\n",
    "valid_indices = torch.arange(49000, 50000)\n",
    "\n",
    "\n",
    "train_and_valid = datasets.CIFAR10(root='/input/', \n",
    "                                   train=True, \n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "train_dataset = Subset(train_and_valid, train_indices)\n",
    "valid_dataset = Subset(train_and_valid, valid_indices)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/input/', \n",
    "                                train=False, \n",
    "                                transform=transforms.ToTensor())\n",
    "\n",
    "#####################################################\n",
    "### Data Loaders\n",
    "#####################################################\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset, \n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          num_workers=8,\n",
    "                          shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         num_workers=8,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NiN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(NiN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.classifier = nn.Sequential(\n",
    "                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                nn.Dropout(0.5),\n",
    "\n",
    "                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n",
    "\n",
    "                )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        logits = x.view(x.size(0), self.num_classes)\n",
    "        probas = torch.softmax(logits, dim=1)\n",
    "        return logits, probas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/100 | Batch 000/192 | Cost: 2.3043\n",
      "Epoch: 001/100 | Batch 120/192 | Cost: 2.0062\n",
      "Epoch: 001/100 Train Acc.: 26.97% | Validation Acc.: 28.60%\n",
      "Time elapsed: 0.36 min\n",
      "Epoch: 002/100 | Batch 000/192 | Cost: 1.8996\n",
      "Epoch: 002/100 | Batch 120/192 | Cost: 1.8640\n",
      "Epoch: 002/100 Train Acc.: 33.31% | Validation Acc.: 32.80%\n",
      "Time elapsed: 0.71 min\n",
      "Epoch: 003/100 | Batch 000/192 | Cost: 1.7248\n",
      "Epoch: 003/100 | Batch 120/192 | Cost: 1.7386\n",
      "Epoch: 003/100 Train Acc.: 36.32% | Validation Acc.: 36.00%\n",
      "Time elapsed: 1.05 min\n",
      "Epoch: 004/100 | Batch 000/192 | Cost: 1.7034\n",
      "Epoch: 004/100 | Batch 120/192 | Cost: 1.5707\n",
      "Epoch: 004/100 Train Acc.: 40.21% | Validation Acc.: 42.70%\n",
      "Time elapsed: 1.39 min\n",
      "Epoch: 005/100 | Batch 000/192 | Cost: 1.6372\n",
      "Epoch: 005/100 | Batch 120/192 | Cost: 1.6354\n",
      "Epoch: 005/100 Train Acc.: 43.71% | Validation Acc.: 45.90%\n",
      "Time elapsed: 1.73 min\n",
      "Epoch: 006/100 | Batch 000/192 | Cost: 1.6369\n",
      "Epoch: 006/100 | Batch 120/192 | Cost: 1.4114\n",
      "Epoch: 006/100 Train Acc.: 47.08% | Validation Acc.: 48.00%\n",
      "Time elapsed: 2.07 min\n",
      "Epoch: 007/100 | Batch 000/192 | Cost: 1.5766\n",
      "Epoch: 007/100 | Batch 120/192 | Cost: 1.5053\n",
      "Epoch: 007/100 Train Acc.: 49.25% | Validation Acc.: 50.80%\n",
      "Time elapsed: 2.42 min\n",
      "Epoch: 008/100 | Batch 000/192 | Cost: 1.4324\n",
      "Epoch: 008/100 | Batch 120/192 | Cost: 1.3724\n",
      "Epoch: 008/100 Train Acc.: 51.86% | Validation Acc.: 51.50%\n",
      "Time elapsed: 2.76 min\n",
      "Epoch: 009/100 | Batch 000/192 | Cost: 1.2979\n",
      "Epoch: 009/100 | Batch 120/192 | Cost: 1.3761\n",
      "Epoch: 009/100 Train Acc.: 54.57% | Validation Acc.: 54.20%\n",
      "Time elapsed: 3.10 min\n",
      "Epoch: 010/100 | Batch 000/192 | Cost: 1.2372\n",
      "Epoch: 010/100 | Batch 120/192 | Cost: 1.2880\n",
      "Epoch: 010/100 Train Acc.: 54.51% | Validation Acc.: 54.50%\n",
      "Time elapsed: 3.45 min\n",
      "Epoch: 011/100 | Batch 000/192 | Cost: 1.2764\n",
      "Epoch: 011/100 | Batch 120/192 | Cost: 1.2328\n",
      "Epoch: 011/100 Train Acc.: 56.15% | Validation Acc.: 57.40%\n",
      "Time elapsed: 3.79 min\n",
      "Epoch: 012/100 | Batch 000/192 | Cost: 1.1678\n",
      "Epoch: 012/100 | Batch 120/192 | Cost: 1.3974\n",
      "Epoch: 012/100 Train Acc.: 56.59% | Validation Acc.: 56.30%\n",
      "Time elapsed: 4.13 min\n",
      "Epoch: 013/100 | Batch 000/192 | Cost: 1.2192\n",
      "Epoch: 013/100 | Batch 120/192 | Cost: 1.3187\n",
      "Epoch: 013/100 Train Acc.: 58.05% | Validation Acc.: 56.90%\n",
      "Time elapsed: 4.48 min\n",
      "Epoch: 014/100 | Batch 000/192 | Cost: 1.1775\n",
      "Epoch: 014/100 | Batch 120/192 | Cost: 1.2567\n",
      "Epoch: 014/100 Train Acc.: 59.74% | Validation Acc.: 59.40%\n",
      "Time elapsed: 4.82 min\n",
      "Epoch: 015/100 | Batch 000/192 | Cost: 1.1685\n",
      "Epoch: 015/100 | Batch 120/192 | Cost: 1.1657\n",
      "Epoch: 015/100 Train Acc.: 61.36% | Validation Acc.: 59.70%\n",
      "Time elapsed: 5.16 min\n",
      "Epoch: 016/100 | Batch 000/192 | Cost: 1.0738\n",
      "Epoch: 016/100 | Batch 120/192 | Cost: 1.1945\n",
      "Epoch: 016/100 Train Acc.: 60.92% | Validation Acc.: 60.30%\n",
      "Time elapsed: 5.51 min\n",
      "Epoch: 017/100 | Batch 000/192 | Cost: 1.1704\n",
      "Epoch: 017/100 | Batch 120/192 | Cost: 1.1047\n",
      "Epoch: 017/100 Train Acc.: 62.12% | Validation Acc.: 62.40%\n",
      "Time elapsed: 5.85 min\n",
      "Epoch: 018/100 | Batch 000/192 | Cost: 1.1363\n",
      "Epoch: 018/100 | Batch 120/192 | Cost: 1.1294\n",
      "Epoch: 018/100 Train Acc.: 63.44% | Validation Acc.: 60.50%\n",
      "Time elapsed: 6.19 min\n",
      "Epoch: 019/100 | Batch 000/192 | Cost: 1.2039\n",
      "Epoch: 019/100 | Batch 120/192 | Cost: 1.1191\n",
      "Epoch: 019/100 Train Acc.: 64.39% | Validation Acc.: 62.50%\n",
      "Time elapsed: 6.54 min\n",
      "Epoch: 020/100 | Batch 000/192 | Cost: 1.0080\n",
      "Epoch: 020/100 | Batch 120/192 | Cost: 0.9763\n",
      "Epoch: 020/100 Train Acc.: 65.41% | Validation Acc.: 63.50%\n",
      "Time elapsed: 6.88 min\n",
      "Epoch: 021/100 | Batch 000/192 | Cost: 1.0146\n",
      "Epoch: 021/100 | Batch 120/192 | Cost: 1.0670\n",
      "Epoch: 021/100 Train Acc.: 64.64% | Validation Acc.: 63.20%\n",
      "Time elapsed: 7.23 min\n",
      "Epoch: 022/100 | Batch 000/192 | Cost: 0.9994\n",
      "Epoch: 022/100 | Batch 120/192 | Cost: 0.9007\n",
      "Epoch: 022/100 Train Acc.: 64.94% | Validation Acc.: 63.20%\n",
      "Time elapsed: 7.57 min\n",
      "Epoch: 023/100 | Batch 000/192 | Cost: 1.0145\n",
      "Epoch: 023/100 | Batch 120/192 | Cost: 1.0259\n",
      "Epoch: 023/100 Train Acc.: 67.81% | Validation Acc.: 65.20%\n",
      "Time elapsed: 7.91 min\n",
      "Epoch: 024/100 | Batch 000/192 | Cost: 0.9608\n",
      "Epoch: 024/100 | Batch 120/192 | Cost: 0.9766\n",
      "Epoch: 024/100 Train Acc.: 67.83% | Validation Acc.: 65.90%\n",
      "Time elapsed: 8.26 min\n",
      "Epoch: 025/100 | Batch 000/192 | Cost: 1.0127\n",
      "Epoch: 025/100 | Batch 120/192 | Cost: 0.9190\n",
      "Epoch: 025/100 Train Acc.: 68.48% | Validation Acc.: 67.10%\n",
      "Time elapsed: 8.60 min\n",
      "Epoch: 026/100 | Batch 000/192 | Cost: 0.8194\n",
      "Epoch: 026/100 | Batch 120/192 | Cost: 0.9307\n",
      "Epoch: 026/100 Train Acc.: 67.93% | Validation Acc.: 68.30%\n",
      "Time elapsed: 8.94 min\n",
      "Epoch: 027/100 | Batch 000/192 | Cost: 0.9170\n",
      "Epoch: 027/100 | Batch 120/192 | Cost: 0.8866\n",
      "Epoch: 027/100 Train Acc.: 69.60% | Validation Acc.: 67.10%\n",
      "Time elapsed: 9.29 min\n",
      "Epoch: 028/100 | Batch 000/192 | Cost: 0.8559\n",
      "Epoch: 028/100 | Batch 120/192 | Cost: 0.7366\n",
      "Epoch: 028/100 Train Acc.: 68.79% | Validation Acc.: 68.30%\n",
      "Time elapsed: 9.63 min\n",
      "Epoch: 029/100 | Batch 000/192 | Cost: 0.9155\n",
      "Epoch: 029/100 | Batch 120/192 | Cost: 0.9683\n",
      "Epoch: 029/100 Train Acc.: 69.49% | Validation Acc.: 65.90%\n",
      "Time elapsed: 9.97 min\n",
      "Epoch: 030/100 | Batch 000/192 | Cost: 0.9341\n",
      "Epoch: 030/100 | Batch 120/192 | Cost: 0.8820\n",
      "Epoch: 030/100 Train Acc.: 70.98% | Validation Acc.: 67.60%\n",
      "Time elapsed: 10.32 min\n",
      "Epoch: 031/100 | Batch 000/192 | Cost: 0.7724\n",
      "Epoch: 031/100 | Batch 120/192 | Cost: 0.7554\n",
      "Epoch: 031/100 Train Acc.: 71.14% | Validation Acc.: 68.50%\n",
      "Time elapsed: 10.66 min\n",
      "Epoch: 032/100 | Batch 000/192 | Cost: 0.8205\n",
      "Epoch: 032/100 | Batch 120/192 | Cost: 0.8623\n",
      "Epoch: 032/100 Train Acc.: 71.59% | Validation Acc.: 68.10%\n",
      "Time elapsed: 11.00 min\n",
      "Epoch: 033/100 | Batch 000/192 | Cost: 0.7735\n",
      "Epoch: 033/100 | Batch 120/192 | Cost: 0.8640\n",
      "Epoch: 033/100 Train Acc.: 71.51% | Validation Acc.: 70.00%\n",
      "Time elapsed: 11.35 min\n",
      "Epoch: 034/100 | Batch 000/192 | Cost: 0.8413\n",
      "Epoch: 034/100 | Batch 120/192 | Cost: 0.6812\n",
      "Epoch: 034/100 Train Acc.: 71.79% | Validation Acc.: 69.10%\n",
      "Time elapsed: 11.69 min\n",
      "Epoch: 035/100 | Batch 000/192 | Cost: 0.8989\n",
      "Epoch: 035/100 | Batch 120/192 | Cost: 0.8966\n",
      "Epoch: 035/100 Train Acc.: 72.58% | Validation Acc.: 70.10%\n",
      "Time elapsed: 12.03 min\n",
      "Epoch: 036/100 | Batch 000/192 | Cost: 0.7702\n",
      "Epoch: 036/100 | Batch 120/192 | Cost: 0.8739\n",
      "Epoch: 036/100 Train Acc.: 72.79% | Validation Acc.: 69.80%\n",
      "Time elapsed: 12.38 min\n",
      "Epoch: 037/100 | Batch 000/192 | Cost: 0.7772\n",
      "Epoch: 037/100 | Batch 120/192 | Cost: 0.7022\n",
      "Epoch: 037/100 Train Acc.: 73.50% | Validation Acc.: 70.80%\n",
      "Time elapsed: 12.73 min\n",
      "Epoch: 038/100 | Batch 000/192 | Cost: 0.7349\n",
      "Epoch: 038/100 | Batch 120/192 | Cost: 0.7438\n",
      "Epoch: 038/100 Train Acc.: 74.09% | Validation Acc.: 70.40%\n",
      "Time elapsed: 13.07 min\n",
      "Epoch: 039/100 | Batch 000/192 | Cost: 0.7220\n",
      "Epoch: 039/100 | Batch 120/192 | Cost: 0.7795\n",
      "Epoch: 039/100 Train Acc.: 73.83% | Validation Acc.: 69.10%\n",
      "Time elapsed: 13.41 min\n",
      "Epoch: 040/100 | Batch 000/192 | Cost: 0.8185\n",
      "Epoch: 040/100 | Batch 120/192 | Cost: 0.6984\n",
      "Epoch: 040/100 Train Acc.: 74.25% | Validation Acc.: 71.70%\n",
      "Time elapsed: 13.75 min\n",
      "Epoch: 041/100 | Batch 000/192 | Cost: 0.6760\n",
      "Epoch: 041/100 | Batch 120/192 | Cost: 0.8673\n",
      "Epoch: 041/100 Train Acc.: 74.26% | Validation Acc.: 70.10%\n",
      "Time elapsed: 14.09 min\n",
      "Epoch: 042/100 | Batch 000/192 | Cost: 0.7651\n",
      "Epoch: 042/100 | Batch 120/192 | Cost: 0.8110\n",
      "Epoch: 042/100 Train Acc.: 75.28% | Validation Acc.: 69.80%\n",
      "Time elapsed: 14.44 min\n",
      "Epoch: 043/100 | Batch 000/192 | Cost: 0.7613\n",
      "Epoch: 043/100 | Batch 120/192 | Cost: 0.7680\n",
      "Epoch: 043/100 Train Acc.: 74.89% | Validation Acc.: 71.30%\n",
      "Time elapsed: 14.78 min\n",
      "Epoch: 044/100 | Batch 000/192 | Cost: 0.7727\n",
      "Epoch: 044/100 | Batch 120/192 | Cost: 0.7951\n",
      "Epoch: 044/100 Train Acc.: 75.00% | Validation Acc.: 71.50%\n",
      "Time elapsed: 15.12 min\n",
      "Epoch: 045/100 | Batch 000/192 | Cost: 0.7168\n",
      "Epoch: 045/100 | Batch 120/192 | Cost: 0.7493\n",
      "Epoch: 045/100 Train Acc.: 76.02% | Validation Acc.: 71.60%\n",
      "Time elapsed: 15.46 min\n",
      "Epoch: 046/100 | Batch 000/192 | Cost: 0.6191\n",
      "Epoch: 046/100 | Batch 120/192 | Cost: 0.6574\n",
      "Epoch: 046/100 Train Acc.: 75.86% | Validation Acc.: 71.00%\n",
      "Time elapsed: 15.81 min\n",
      "Epoch: 047/100 | Batch 000/192 | Cost: 0.7041\n",
      "Epoch: 047/100 | Batch 120/192 | Cost: 0.6676\n",
      "Epoch: 047/100 Train Acc.: 76.36% | Validation Acc.: 71.00%\n",
      "Time elapsed: 16.15 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 048/100 | Batch 000/192 | Cost: 0.6867\n",
      "Epoch: 048/100 | Batch 120/192 | Cost: 0.7413\n",
      "Epoch: 048/100 Train Acc.: 75.81% | Validation Acc.: 70.90%\n",
      "Time elapsed: 16.50 min\n",
      "Epoch: 049/100 | Batch 000/192 | Cost: 0.6400\n",
      "Epoch: 049/100 | Batch 120/192 | Cost: 0.6616\n",
      "Epoch: 049/100 Train Acc.: 77.20% | Validation Acc.: 71.60%\n",
      "Time elapsed: 16.84 min\n",
      "Epoch: 050/100 | Batch 000/192 | Cost: 0.5869\n",
      "Epoch: 050/100 | Batch 120/192 | Cost: 0.7880\n",
      "Epoch: 050/100 Train Acc.: 76.54% | Validation Acc.: 73.80%\n",
      "Time elapsed: 17.19 min\n",
      "Epoch: 051/100 | Batch 000/192 | Cost: 0.6346\n",
      "Epoch: 051/100 | Batch 120/192 | Cost: 0.7546\n",
      "Epoch: 051/100 Train Acc.: 76.56% | Validation Acc.: 71.40%\n",
      "Time elapsed: 17.53 min\n",
      "Epoch: 052/100 | Batch 000/192 | Cost: 0.7384\n",
      "Epoch: 052/100 | Batch 120/192 | Cost: 0.6931\n",
      "Epoch: 052/100 Train Acc.: 78.14% | Validation Acc.: 72.40%\n",
      "Time elapsed: 17.87 min\n",
      "Epoch: 053/100 | Batch 000/192 | Cost: 0.6469\n",
      "Epoch: 053/100 | Batch 120/192 | Cost: 0.5473\n",
      "Epoch: 053/100 Train Acc.: 77.86% | Validation Acc.: 72.40%\n",
      "Time elapsed: 18.21 min\n",
      "Epoch: 054/100 | Batch 000/192 | Cost: 0.7120\n",
      "Epoch: 054/100 | Batch 120/192 | Cost: 0.6427\n",
      "Epoch: 054/100 Train Acc.: 77.65% | Validation Acc.: 70.70%\n",
      "Time elapsed: 18.56 min\n",
      "Epoch: 055/100 | Batch 000/192 | Cost: 0.6419\n",
      "Epoch: 055/100 | Batch 120/192 | Cost: 0.6030\n",
      "Epoch: 055/100 Train Acc.: 78.88% | Validation Acc.: 72.70%\n",
      "Time elapsed: 18.90 min\n",
      "Epoch: 056/100 | Batch 000/192 | Cost: 0.6753\n",
      "Epoch: 056/100 | Batch 120/192 | Cost: 0.6162\n",
      "Epoch: 056/100 Train Acc.: 78.55% | Validation Acc.: 72.20%\n",
      "Time elapsed: 19.24 min\n",
      "Epoch: 057/100 | Batch 000/192 | Cost: 0.6220\n",
      "Epoch: 057/100 | Batch 120/192 | Cost: 0.5362\n",
      "Epoch: 057/100 Train Acc.: 78.40% | Validation Acc.: 71.90%\n",
      "Time elapsed: 19.59 min\n",
      "Epoch: 058/100 | Batch 000/192 | Cost: 0.6182\n",
      "Epoch: 058/100 | Batch 120/192 | Cost: 0.6040\n",
      "Epoch: 058/100 Train Acc.: 79.04% | Validation Acc.: 72.20%\n",
      "Time elapsed: 19.93 min\n",
      "Epoch: 059/100 | Batch 000/192 | Cost: 0.5566\n",
      "Epoch: 059/100 | Batch 120/192 | Cost: 0.5750\n",
      "Epoch: 059/100 Train Acc.: 77.68% | Validation Acc.: 72.10%\n",
      "Time elapsed: 20.27 min\n",
      "Epoch: 060/100 | Batch 000/192 | Cost: 0.5580\n",
      "Epoch: 060/100 | Batch 120/192 | Cost: 0.6459\n",
      "Epoch: 060/100 Train Acc.: 79.08% | Validation Acc.: 72.10%\n",
      "Time elapsed: 20.61 min\n",
      "Epoch: 061/100 | Batch 000/192 | Cost: 0.5860\n",
      "Epoch: 061/100 | Batch 120/192 | Cost: 0.4901\n",
      "Epoch: 061/100 Train Acc.: 79.58% | Validation Acc.: 72.60%\n",
      "Time elapsed: 20.95 min\n",
      "Epoch: 062/100 | Batch 000/192 | Cost: 0.6107\n",
      "Epoch: 062/100 | Batch 120/192 | Cost: 0.5956\n",
      "Epoch: 062/100 Train Acc.: 79.17% | Validation Acc.: 71.70%\n",
      "Time elapsed: 21.30 min\n",
      "Epoch: 063/100 | Batch 000/192 | Cost: 0.6433\n",
      "Epoch: 063/100 | Batch 120/192 | Cost: 0.6782\n",
      "Epoch: 063/100 Train Acc.: 79.71% | Validation Acc.: 72.20%\n",
      "Time elapsed: 21.64 min\n",
      "Epoch: 064/100 | Batch 000/192 | Cost: 0.5472\n",
      "Epoch: 064/100 | Batch 120/192 | Cost: 0.5938\n",
      "Epoch: 064/100 Train Acc.: 80.93% | Validation Acc.: 73.40%\n",
      "Time elapsed: 21.98 min\n",
      "Epoch: 065/100 | Batch 000/192 | Cost: 0.4908\n",
      "Epoch: 065/100 | Batch 120/192 | Cost: 0.6274\n",
      "Epoch: 065/100 Train Acc.: 79.95% | Validation Acc.: 72.80%\n",
      "Time elapsed: 22.33 min\n",
      "Epoch: 066/100 | Batch 000/192 | Cost: 0.6660\n",
      "Epoch: 066/100 | Batch 120/192 | Cost: 0.6161\n",
      "Epoch: 066/100 Train Acc.: 80.60% | Validation Acc.: 73.10%\n",
      "Time elapsed: 22.67 min\n",
      "Epoch: 067/100 | Batch 000/192 | Cost: 0.5471\n",
      "Epoch: 067/100 | Batch 120/192 | Cost: 0.5267\n",
      "Epoch: 067/100 Train Acc.: 80.81% | Validation Acc.: 73.20%\n",
      "Time elapsed: 23.01 min\n",
      "Epoch: 068/100 | Batch 000/192 | Cost: 0.5803\n",
      "Epoch: 068/100 | Batch 120/192 | Cost: 0.4796\n",
      "Epoch: 068/100 Train Acc.: 80.71% | Validation Acc.: 73.70%\n",
      "Time elapsed: 23.35 min\n",
      "Epoch: 069/100 | Batch 000/192 | Cost: 0.5825\n",
      "Epoch: 069/100 | Batch 120/192 | Cost: 0.6337\n",
      "Epoch: 069/100 Train Acc.: 80.92% | Validation Acc.: 73.60%\n",
      "Time elapsed: 23.70 min\n",
      "Epoch: 070/100 | Batch 000/192 | Cost: 0.5606\n",
      "Epoch: 070/100 | Batch 120/192 | Cost: 0.5830\n",
      "Epoch: 070/100 Train Acc.: 81.00% | Validation Acc.: 72.10%\n",
      "Time elapsed: 24.04 min\n",
      "Epoch: 071/100 | Batch 000/192 | Cost: 0.5272\n",
      "Epoch: 071/100 | Batch 120/192 | Cost: 0.4862\n",
      "Epoch: 071/100 Train Acc.: 80.99% | Validation Acc.: 72.60%\n",
      "Time elapsed: 24.38 min\n",
      "Epoch: 072/100 | Batch 000/192 | Cost: 0.4753\n",
      "Epoch: 072/100 | Batch 120/192 | Cost: 0.3925\n",
      "Epoch: 072/100 Train Acc.: 81.14% | Validation Acc.: 72.60%\n",
      "Time elapsed: 24.72 min\n",
      "Epoch: 073/100 | Batch 000/192 | Cost: 0.5307\n",
      "Epoch: 073/100 | Batch 120/192 | Cost: 0.5553\n",
      "Epoch: 073/100 Train Acc.: 80.76% | Validation Acc.: 71.80%\n",
      "Time elapsed: 25.07 min\n",
      "Epoch: 074/100 | Batch 000/192 | Cost: 0.5315\n",
      "Epoch: 074/100 | Batch 120/192 | Cost: 0.4984\n",
      "Epoch: 074/100 Train Acc.: 81.38% | Validation Acc.: 73.10%\n",
      "Time elapsed: 25.41 min\n",
      "Epoch: 075/100 | Batch 000/192 | Cost: 0.4508\n",
      "Epoch: 075/100 | Batch 120/192 | Cost: 0.5322\n",
      "Epoch: 075/100 Train Acc.: 80.56% | Validation Acc.: 73.20%\n",
      "Time elapsed: 25.75 min\n",
      "Epoch: 076/100 | Batch 000/192 | Cost: 0.5022\n",
      "Epoch: 076/100 | Batch 120/192 | Cost: 0.4590\n",
      "Epoch: 076/100 Train Acc.: 81.43% | Validation Acc.: 73.10%\n",
      "Time elapsed: 26.10 min\n",
      "Epoch: 077/100 | Batch 000/192 | Cost: 0.5534\n",
      "Epoch: 077/100 | Batch 120/192 | Cost: 0.5921\n",
      "Epoch: 077/100 Train Acc.: 82.41% | Validation Acc.: 72.30%\n",
      "Time elapsed: 26.44 min\n",
      "Epoch: 078/100 | Batch 000/192 | Cost: 0.4366\n",
      "Epoch: 078/100 | Batch 120/192 | Cost: 0.4836\n",
      "Epoch: 078/100 Train Acc.: 81.57% | Validation Acc.: 71.20%\n",
      "Time elapsed: 26.79 min\n",
      "Epoch: 079/100 | Batch 000/192 | Cost: 0.4705\n",
      "Epoch: 079/100 | Batch 120/192 | Cost: 0.4931\n",
      "Epoch: 079/100 Train Acc.: 82.16% | Validation Acc.: 72.60%\n",
      "Time elapsed: 27.13 min\n",
      "Epoch: 080/100 | Batch 000/192 | Cost: 0.4767\n",
      "Epoch: 080/100 | Batch 120/192 | Cost: 0.6313\n",
      "Epoch: 080/100 Train Acc.: 82.34% | Validation Acc.: 71.30%\n",
      "Time elapsed: 27.47 min\n",
      "Epoch: 081/100 | Batch 000/192 | Cost: 0.6211\n",
      "Epoch: 081/100 | Batch 120/192 | Cost: 0.5138\n",
      "Epoch: 081/100 Train Acc.: 82.03% | Validation Acc.: 71.90%\n",
      "Time elapsed: 27.81 min\n",
      "Epoch: 082/100 | Batch 000/192 | Cost: 0.4495\n",
      "Epoch: 082/100 | Batch 120/192 | Cost: 0.4917\n",
      "Epoch: 082/100 Train Acc.: 81.23% | Validation Acc.: 71.60%\n",
      "Time elapsed: 28.15 min\n",
      "Epoch: 083/100 | Batch 000/192 | Cost: 0.3803\n",
      "Epoch: 083/100 | Batch 120/192 | Cost: 0.6247\n",
      "Epoch: 083/100 Train Acc.: 82.77% | Validation Acc.: 74.40%\n",
      "Time elapsed: 28.49 min\n",
      "Epoch: 084/100 | Batch 000/192 | Cost: 0.5032\n",
      "Epoch: 084/100 | Batch 120/192 | Cost: 0.4318\n",
      "Epoch: 084/100 Train Acc.: 82.45% | Validation Acc.: 72.90%\n",
      "Time elapsed: 28.84 min\n",
      "Epoch: 085/100 | Batch 000/192 | Cost: 0.4828\n",
      "Epoch: 085/100 | Batch 120/192 | Cost: 0.4842\n",
      "Epoch: 085/100 Train Acc.: 82.75% | Validation Acc.: 72.40%\n",
      "Time elapsed: 29.18 min\n",
      "Epoch: 086/100 | Batch 000/192 | Cost: 0.5426\n",
      "Epoch: 086/100 | Batch 120/192 | Cost: 0.5699\n",
      "Epoch: 086/100 Train Acc.: 83.32% | Validation Acc.: 73.70%\n",
      "Time elapsed: 29.52 min\n",
      "Epoch: 087/100 | Batch 000/192 | Cost: 0.4077\n",
      "Epoch: 087/100 | Batch 120/192 | Cost: 0.5206\n",
      "Epoch: 087/100 Train Acc.: 83.15% | Validation Acc.: 73.70%\n",
      "Time elapsed: 29.86 min\n",
      "Epoch: 088/100 | Batch 000/192 | Cost: 0.4867\n",
      "Epoch: 088/100 | Batch 120/192 | Cost: 0.5010\n",
      "Epoch: 088/100 Train Acc.: 82.91% | Validation Acc.: 71.80%\n",
      "Time elapsed: 30.21 min\n",
      "Epoch: 089/100 | Batch 000/192 | Cost: 0.3858\n",
      "Epoch: 089/100 | Batch 120/192 | Cost: 0.4805\n",
      "Epoch: 089/100 Train Acc.: 83.76% | Validation Acc.: 72.60%\n",
      "Time elapsed: 30.55 min\n",
      "Epoch: 090/100 | Batch 000/192 | Cost: 0.4267\n",
      "Epoch: 090/100 | Batch 120/192 | Cost: 0.4430\n",
      "Epoch: 090/100 Train Acc.: 83.42% | Validation Acc.: 72.60%\n",
      "Time elapsed: 30.89 min\n",
      "Epoch: 091/100 | Batch 000/192 | Cost: 0.4524\n",
      "Epoch: 091/100 | Batch 120/192 | Cost: 0.5378\n",
      "Epoch: 091/100 Train Acc.: 82.74% | Validation Acc.: 72.70%\n",
      "Time elapsed: 31.23 min\n",
      "Epoch: 092/100 | Batch 000/192 | Cost: 0.4259\n",
      "Epoch: 092/100 | Batch 120/192 | Cost: 0.4336\n",
      "Epoch: 092/100 Train Acc.: 84.01% | Validation Acc.: 73.40%\n",
      "Time elapsed: 31.58 min\n",
      "Epoch: 093/100 | Batch 000/192 | Cost: 0.5187\n",
      "Epoch: 093/100 | Batch 120/192 | Cost: 0.5380\n",
      "Epoch: 093/100 Train Acc.: 84.08% | Validation Acc.: 72.70%\n",
      "Time elapsed: 31.92 min\n",
      "Epoch: 094/100 | Batch 000/192 | Cost: 0.4666\n",
      "Epoch: 094/100 | Batch 120/192 | Cost: 0.4567\n",
      "Epoch: 094/100 Train Acc.: 83.87% | Validation Acc.: 72.00%\n",
      "Time elapsed: 32.26 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 095/100 | Batch 000/192 | Cost: 0.5056\n",
      "Epoch: 095/100 | Batch 120/192 | Cost: 0.3520\n",
      "Epoch: 095/100 Train Acc.: 84.24% | Validation Acc.: 74.90%\n",
      "Time elapsed: 32.60 min\n",
      "Epoch: 096/100 | Batch 000/192 | Cost: 0.4989\n",
      "Epoch: 096/100 | Batch 120/192 | Cost: 0.4355\n",
      "Epoch: 096/100 Train Acc.: 83.62% | Validation Acc.: 73.20%\n",
      "Time elapsed: 32.94 min\n",
      "Epoch: 097/100 | Batch 000/192 | Cost: 0.4089\n",
      "Epoch: 097/100 | Batch 120/192 | Cost: 0.3521\n",
      "Epoch: 097/100 Train Acc.: 83.88% | Validation Acc.: 73.70%\n",
      "Time elapsed: 33.29 min\n",
      "Epoch: 098/100 | Batch 000/192 | Cost: 0.4364\n",
      "Epoch: 098/100 | Batch 120/192 | Cost: 0.4730\n",
      "Epoch: 098/100 Train Acc.: 84.07% | Validation Acc.: 73.60%\n",
      "Time elapsed: 33.63 min\n",
      "Epoch: 099/100 | Batch 000/192 | Cost: 0.5375\n",
      "Epoch: 099/100 | Batch 120/192 | Cost: 0.4485\n",
      "Epoch: 099/100 Train Acc.: 84.07% | Validation Acc.: 72.80%\n",
      "Time elapsed: 33.97 min\n",
      "Epoch: 100/100 | Batch 000/192 | Cost: 0.4016\n",
      "Epoch: 100/100 | Batch 120/192 | Cost: 0.5793\n",
      "Epoch: 100/100 Train Acc.: 82.96% | Validation Acc.: 73.40%\n",
      "Time elapsed: 34.31 min\n",
      "Total Training Time: 34.31 min\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = NiN(NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)  \n",
    "def compute_accuracy(model, data_loader, device):\n",
    "    correct_pred, num_examples = 0, 0\n",
    "    for i, (features, targets) in enumerate(data_loader):\n",
    "            \n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        logits, probas = model(features)\n",
    "        _, predicted_labels = torch.max(probas, 1)\n",
    "        num_examples += targets.size(0)\n",
    "        correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100\n",
    "    \n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (features, targets) in enumerate(train_loader):\n",
    "    \n",
    "        ### PREPARE MINIBATCH\n",
    "        features = features.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "            \n",
    "        ### FORWARD AND BACK PROP\n",
    "        logits, probas = model(features)\n",
    "        cost = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        cost.backward()\n",
    "        \n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 120:\n",
    "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} |' \n",
    "                   f' Cost: {cost:.4f}')\n",
    "\n",
    "    # no need to build the computation graph for backprop when computing accuracy\n",
    "    with torch.set_grad_enabled(False):\n",
    "        train_acc = compute_accuracy(model, train_loader, device=DEVICE)\n",
    "        valid_acc = compute_accuracy(model, valid_loader, device=DEVICE)\n",
    "        print(f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} Train Acc.: {train_acc:.2f}%'\n",
    "              f' | Validation Acc.: {valid_acc:.2f}%')\n",
    "        \n",
    "    elapsed = (time.time() - start_time)/60\n",
    "    print(f'Time elapsed: {elapsed:.2f} min')\n",
    "  \n",
    "elapsed = (time.time() - start_time)/60\n",
    "print(f'Total Training Time: {elapsed:.2f} min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
